{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335c2b86eab4431aaeffbe7e995aaaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "페이지 크롤링:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "페이지 1 로드 중: https://smithery.ai/?q=is%3Adeployed&page=1\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Sequential Thinking\n",
      "  - 서버 데이터 추출: Desktop Commander\n",
      "  - 서버 데이터 추출: Github\n",
      "  - 서버 데이터 추출: Think Tool Server\n",
      "  - 서버 데이터 추출: Brave Search\n",
      "  - 서버 데이터 추출: Magic MCP\n",
      "  - 서버 데이터 추출: Browserbase\n",
      "  - 서버 데이터 추출: Claude Code MCP Server\n",
      "  - 서버 데이터 추출: VeyraX MCP\n",
      "  - 서버 데이터 추출: Neon Database\n",
      "  - 서버 데이터 추출: Exa Search\n",
      "  - 서버 데이터 추출: Perplexity Search\n",
      "  - 서버 데이터 추출: Fetch\n",
      "  - 서버 데이터 추출: E2B\n",
      "  - 서버 데이터 추출: Supabase MCP Server\n",
      "  - 서버 데이터 추출: Figma API Integration\n",
      "  - 서버 데이터 추출: Todoist MCP Server\n",
      "  - 서버 데이터 추출: Gemini Thinking Server\n",
      "  - 서버 데이터 추출: Notion API\n",
      "  - 서버 데이터 추출: Stagehand\n",
      "페이지 1 완료: 20개 서버 추출 (누적: 20개)\n",
      "다음 요청까지 1.48초 대기 중...\n",
      "\n",
      "페이지 2 로드 중: https://smithery.ai/?q=is%3Adeployed&page=2\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Linear MCP Server\n",
      "  - 서버 데이터 추출: FFmpeg Video Processor\n",
      "  - 서버 데이터 추출: Hyperbrowser\n",
      "  - 서버 데이터 추출: Aindreyway Codex Keeper\n",
      "  - 서버 데이터 추출: DuckDuckGo Search Server\n",
      "  - 서버 데이터 추출: Playwright\n",
      "  - 서버 데이터 추출: Linear MCP Server\n",
      "  - 서버 데이터 추출: Code MCP\n",
      "  - 서버 데이터 추출: ClickUp MCP Server\n",
      "  - 서버 데이터 추출: Crypto Price & Market Analysis Server\n",
      "  - 서버 데이터 추출: Fetch MCP Server\n",
      "  - 서버 데이터 추출: Sequential Thinking\n",
      "  - 서버 데이터 추출: Google Workspace Server\n",
      "  - 서버 데이터 추출: Google Workspace MCP Server\n",
      "  - 서버 데이터 추출: Mermaid Diagram Generator\n",
      "  - 서버 데이터 추출: Airbnb Search and Listing Server\n",
      "  - 서버 데이터 추출: Multi-Model Advisor\n",
      "  - 서버 데이터 추출: Hacker News\n",
      "  - 서버 데이터 추출: MySQL Server\n",
      "  - 서버 데이터 추출: Instagram Engagement Analysis\n",
      "페이지 2 완료: 20개 서버 추출 (누적: 40개)\n",
      "다음 요청까지 2.04초 대기 중...\n",
      "\n",
      "페이지 3 로드 중: https://smithery.ai/?q=is%3Adeployed&page=3\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Markdown Downloader\n",
      "  - 서버 데이터 추출: Starwind UI MCP Server\n",
      "  - 서버 데이터 추출: Wolfram Alpha\n",
      "  - 서버 데이터 추출: DeepView\n",
      "  - 서버 데이터 추출: Tavily MCP Server\n",
      "  - 서버 데이터 추출: Lunchmoney MCP Server\n",
      "  - 서버 데이터 추출: Zonos TTS Integration\n",
      "  - 서버 데이터 추출: Hass-MCP\n",
      "  - 서버 데이터 추출: TaskManager\n",
      "  - 서버 데이터 추출: File System\n",
      "  - 서버 데이터 추출: YouTube Transcript Server\n",
      "  - 서버 데이터 추출: Todoist-mcp-server-extended\n",
      "  - 서버 데이터 추출: Package Version\n",
      "  - 서버 데이터 추출: Claude Code MCP Server\n",
      "  - 서버 데이터 추출: Perplexity Deep Research\n",
      "  - 서버 데이터 추출: Replicate Flux MCP\n",
      "  - 서버 데이터 추출: n8n Workflow Builder\n",
      "  - 서버 데이터 추출: Graphlit\n",
      "  - 서버 데이터 추출: Trello Server\n",
      "  - 서버 데이터 추출: Figma MCP Server\n",
      "페이지 3 완료: 20개 서버 추출 (누적: 60개)\n",
      "다음 요청까지 1.57초 대기 중...\n",
      "\n",
      "페이지 4 로드 중: https://smithery.ai/?q=is%3Adeployed&page=4\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Knowledge Graph Memory Server\n",
      "  - 서버 데이터 추출: Game Engine Server\n",
      "  - 서버 데이터 추출: Mixpanel Integration\n",
      "  - 서버 데이터 추출: PostgreSQL Database Management Server\n",
      "  - 서버 데이터 추출: OpenRouter MCP Server\n",
      "  - 서버 데이터 추출: Weather\n",
      "  - 서버 데이터 추출: Supabase Server\n",
      "  - 서버 데이터 추출: YouTube MCP Server\n",
      "  - 서버 데이터 추출: Tavily\n",
      "  - 서버 데이터 추출: Multi Fetch MCP Server\n",
      "  - 서버 데이터 추출: Jina AI\n",
      "  - 서버 데이터 추출: Fetch Server\n",
      "  - 서버 데이터 추출: Docx Document Processing Service\n",
      "  - 서버 데이터 추출: MCP Server Starter\n",
      "  - 서버 데이터 추출: JigsawStack Image Generation\n",
      "  - 서버 데이터 추출: Notion MCP Server\n",
      "  - 서버 데이터 추출: Feishu(飞书) Integration Server\n",
      "  - 서버 데이터 추출: HotNews Server\n",
      "  - 서버 데이터 추출: Persistent Knowledge Graph\n",
      "  - 서버 데이터 추출: UnityMCP\n",
      "페이지 4 완료: 20개 서버 추출 (누적: 80개)\n",
      "다음 요청까지 2.58초 대기 중...\n",
      "\n",
      "페이지 5 로드 중: https://smithery.ai/?q=is%3Adeployed&page=5\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Airtable Server\n",
      "  - 서버 데이터 추출: Pandoc Document Conversion\n",
      "  - 서버 데이터 추출: Linear MCP Server\n",
      "  - 서버 데이터 추출: Serper Search and Scrape\n",
      "  - 서버 데이터 추출: Onyx MCP Server\n",
      "  - 서버 데이터 추출: Web Research Server\n",
      "  - 서버 데이터 추출: Desktop Commander\n",
      "  - 서버 데이터 추출: Gitingest MCP Server\n",
      "  - 서버 데이터 추출: Firebase MCP Server\n",
      "  - 서버 데이터 추출: Unsplash Search\n",
      "  - 서버 데이터 추출: Excel\n",
      "  - 서버 데이터 추출: WinTerm\n",
      "  - 서버 데이터 추출: Ableton Live Integration\n",
      "  - 서버 데이터 추출: Web Research Server\n",
      "  - 서버 데이터 추출: Qdrant Server\n",
      "  - 서버 데이터 추출: File Context Server\n",
      "  - 서버 데이터 추출: Replicate\n",
      "  - 서버 데이터 추출: Any OpenAI Compatible API Integrations\n",
      "  - 서버 데이터 추출: Oxylabs MCP\n",
      "  - 서버 데이터 추출: Browser Automation Agent\n",
      "페이지 5 완료: 20개 서버 추출 (누적: 100개)\n",
      "다음 요청까지 2.66초 대기 중...\n",
      "\n",
      "페이지 6 로드 중: https://smithery.ai/?q=is%3Adeployed&page=6\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: UI Flowchart Creator\n",
      "  - 서버 데이터 추출: Crypto_MCP\n",
      "  - 서버 데이터 추출: GitLab\n",
      "  - 서버 데이터 추출: Linear\n",
      "  - 서버 데이터 추출: Azure DevOps Integration\n",
      "  - 서버 데이터 추출: AI 图像生成服务\n",
      "  - 서버 데이터 추출: GitHub\n",
      "  - 서버 데이터 추출: Metabase Integration Server\n",
      "  - 서버 데이터 추출: Slack\n",
      "  - 서버 데이터 추출: OSINT Server\n",
      "  - 서버 데이터 추출: Contentful Management Server\n",
      "  - 서버 데이터 추출: NPX Fetch\n",
      "  - 서버 데이터 추출: Smart-Thinking\n",
      "  - 서버 데이터 추출: YouTube Transcript Server\n",
      "  - 서버 데이터 추출: PubMedSearch\n",
      "  - 서버 데이터 추출: Pushover Notification\n",
      "  - 서버 데이터 추출: Perplexity Chat MCP Server\n",
      "  - 서버 데이터 추출: Discord MCP Server\n",
      "  - 서버 데이터 추출: Todoist Integration\n",
      "  - 서버 데이터 추출: React MCP\n",
      "페이지 6 완료: 20개 서버 추출 (누적: 120개)\n",
      "다음 요청까지 1.88초 대기 중...\n",
      "\n",
      "페이지 7 로드 중: https://smithery.ai/?q=is%3Adeployed&page=7\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: DocsFetcher\n",
      "  - 서버 데이터 추출: Perplexity Server\n",
      "  - 서버 데이터 추출: Youtube Transcript\n",
      "  - 서버 데이터 추출: Unity MCP Integration\n",
      "  - 서버 데이터 추출: Sequential Thinking Tools\n",
      "  - 서버 데이터 추출: MCP Fetch\n",
      "  - 서버 데이터 추출: AutoGen Server\n",
      "  - 서버 데이터 추출: Google Search Server\n",
      "  - 서버 데이터 추출: MySQL MCP Server\n",
      "  - 서버 데이터 추출: Obsidian Omnisearch\n",
      "  - 서버 데이터 추출: ClickUp MCP Server\n",
      "  - 서버 데이터 추출: MySQL MCP Server\n",
      "  - 서버 데이터 추출: Monday.com MCP Server\n",
      "  - 서버 데이터 추출: Google Maps\n",
      "  - 서버 데이터 추출: Greeting\n",
      "  - 서버 데이터 추출: Mavae Image Toolbox\n",
      "  - 서버 데이터 추출: DeepLucid3D UCPF Server\n",
      "  - 서버 데이터 추출: Unity Game Engine\n",
      "  - 서버 데이터 추출: Advanced PocketBase Server V2\n",
      "  - 서버 데이터 추출: Xano MCP Server\n",
      "페이지 7 완료: 20개 서버 추출 (누적: 140개)\n",
      "다음 요청까지 1.86초 대기 중...\n",
      "\n",
      "페이지 8 로드 중: https://smithery.ai/?q=is%3Adeployed&page=8\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Jira Context MCP\n",
      "  - 서버 데이터 추출: Search1API MCP Server\n",
      "  - 서버 데이터 추출: SERP API Server\n",
      "  - 서버 데이터 추출: Apple Tools Integration\n",
      "  - 서버 데이터 추출: 飞书多维表格\n",
      "  - 서버 데이터 추출: Everart\n",
      "  - 서버 데이터 추출: PostgreSQL MCP Server\n",
      "  - 서버 데이터 추출: Think MCP Server\n",
      "  - 서버 데이터 추출: Database Explorer\n",
      "  - 서버 데이터 추출: DocsFetcher\n",
      "  - 서버 데이터 추출: Local Utilities\n",
      "  - 서버 데이터 추출: Playwright MCP\n",
      "  - 서버 데이터 추출: Doc Scraper\n",
      "  - 서버 데이터 추출: MCP Server Semgrep\n",
      "  - 서버 데이터 추출: Google Drive server\n",
      "  - 서버 데이터 추출: JigsawStack AI Web Scraper\n",
      "  - 서버 데이터 추출: Textube\n",
      "  - 서버 데이터 추출: Enzyme\n",
      "  - 서버 데이터 추출: Datadog API Integration\n",
      "  - 서버 데이터 추출: DuckDB Knowledge Graph Memory Server\n",
      "페이지 8 완료: 20개 서버 추출 (누적: 160개)\n",
      "다음 요청까지 2.04초 대기 중...\n",
      "\n",
      "페이지 9 로드 중: https://smithery.ai/?q=is%3Adeployed&page=9\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Spotify Server\n",
      "  - 서버 데이터 추출: SQLite Server\n",
      "  - 서버 데이터 추출: Audiense Insights\n",
      "  - 서버 데이터 추출: Domain Search - No API key required.\n",
      "  - 서버 데이터 추출: PubMed MCP Server\n",
      "  - 서버 데이터 추출: Kagi\n",
      "  - 서버 데이터 추출: Luma MCP Server\n",
      "  - 서버 데이터 추출: MCP Servers\n",
      "  - 서버 데이터 추출: Railway MCP Server\n",
      "  - 서버 데이터 추출: National Parks Server\n",
      "  - 서버 데이터 추출: AIO-MCP Server\n",
      "  - 서버 데이터 추출: Configurable Puppeteer Server\n",
      "  - 서버 데이터 추출: Figma MCP Server\n",
      "  - 서버 데이터 추출: CiteAssist MCP\n",
      "  - 서버 데이터 추출: Mcp Security Audit\n",
      "  - 서버 데이터 추출: Alpha Vantage Stock Server\n",
      "  - 서버 데이터 추출: Algorand MCP Server\n",
      "  - 서버 데이터 추출: Time MCP Server\n",
      "  - 서버 데이터 추출: Exa MCP\n",
      "  - 서버 데이터 추출: Google Calendar\n",
      "페이지 9 완료: 20개 서버 추출 (누적: 180개)\n",
      "다음 요청까지 2.55초 대기 중...\n",
      "\n",
      "페이지 10 로드 중: https://smithery.ai/?q=is%3Adeployed&page=10\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Google Search Console\n",
      "  - 서버 데이터 추출: Drawing Tool for AI Assistants\n",
      "  - 서버 데이터 추출: Talk to Figma MCP\n",
      "  - 서버 데이터 추출: Helius\n",
      "  - 서버 데이터 추출: Asana Integration Server\n",
      "  - 서버 데이터 추출: Content Summarizer Server\n",
      "  - 서버 데이터 추출: VirusTotal Server\n",
      "  - 서버 데이터 추출: Terminal MCP Server\n",
      "  - 서버 데이터 추출: Excel File Processing Server\n",
      "  - 서버 데이터 추출: Erick Wendel Contributions\n",
      "  - 서버 데이터 추출: Mercury MCP\n",
      "  - 서버 데이터 추출: Shodan Server\n",
      "  - 서버 데이터 추출: Pinterest MCP Server\n",
      "  - 서버 데이터 추출: Vercel API Integration\n",
      "  - 서버 데이터 추출: n8n Assistant\n",
      "  - 서버 데이터 추출: Gupiao\n",
      "  - 서버 데이터 추출: Shell Server\n",
      "  - 서버 데이터 추출: Jenkins MCP\n",
      "  - 서버 데이터 추출: Coin MCP Server\n",
      "  - 서버 데이터 추출: Google Scholar MCP Server\n",
      "페이지 10 완료: 20개 서버 추출 (누적: 200개)\n",
      "다음 요청까지 2.38초 대기 중...\n",
      "\n",
      "페이지 11 로드 중: https://smithery.ai/?q=is%3Adeployed&page=11\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: ABAP Development Tools Server\n",
      "  - 서버 데이터 추출: Azure MCP\n",
      "  - 서버 데이터 추출: Screenshot Server\n",
      "  - 서버 데이터 추출: Localhost Browser Console and Network logs\n",
      "  - 서버 데이터 추출: Think Tool\n",
      "  - 서버 데이터 추출: Email Server\n",
      "  - 서버 데이터 추출: Hugging Face MCP Server\n",
      "  - 서버 데이터 추출: SupaUI MCP\n",
      "  - 서버 데이터 추출: iTerm MCP\n",
      "  - 서버 데이터 추출: Gmail GAS\n",
      "  - 서버 데이터 추출: Package Docs\n",
      "  - 서버 데이터 추출: Weather\n",
      "  - 서버 데이터 추출: The Verge News Server\n",
      "  - 서버 데이터 추출: Etherscan Tools\n",
      "  - 서버 데이터 추출: Youtube Translate\n",
      "  - 서버 데이터 추출: MCP-Sentry\n",
      "  - 서버 데이터 추출: Vibe Check\n",
      "  - 서버 데이터 추출: Prospect Research Server\n",
      "  - 서버 데이터 추출: Kagi Search\n",
      "  - 서버 데이터 추출: Fetch Browser\n",
      "페이지 11 완료: 20개 서버 추출 (누적: 220개)\n",
      "다음 요청까지 2.11초 대기 중...\n",
      "\n",
      "페이지 12 로드 중: https://smithery.ai/?q=is%3Adeployed&page=12\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Twitter Server\n",
      "  - 서버 데이터 추출: Flutter Inspector\n",
      "  - 서버 데이터 추출: MSSQL Database Connector\n",
      "  - 서버 데이터 추출: Canvas MCP\n",
      "  - 서버 데이터 추출: Swagger MCP Server\n",
      "  - 서버 데이터 추출: Financial Data Server\n",
      "  - 서버 데이터 추출: LinkedIn Browser\n",
      "  - 서버 데이터 추출: SingleStore MCP Server\n",
      "  - 서버 데이터 추출: Simple Notes MCP Server\n",
      "  - 서버 데이터 추출: Salesforce Server\n",
      "  - 서버 데이터 추출: Pokémcp\n",
      "  - 서버 데이터 추출: Databutton\n",
      "  - 서버 데이터 추출: App Market Intelligence\n",
      "  - 서버 데이터 추출: Email sending server\n",
      "  - 서버 데이터 추출: PubMed Search\n",
      "  - 서버 데이터 추출: Google Workspace Server\n",
      "  - 서버 데이터 추출: Time Server\n",
      "  - 서버 데이터 추출: Spotify\n",
      "  - 서버 데이터 추출: TweetBinder\n",
      "  - 서버 데이터 추출: PubMed Enhanced Search Server\n",
      "페이지 12 완료: 20개 서버 추출 (누적: 240개)\n",
      "다음 요청까지 2.50초 대기 중...\n",
      "\n",
      "페이지 13 로드 중: https://smithery.ai/?q=is%3Adeployed&page=13\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Time Server\n",
      "  - 서버 데이터 추출: ScrapeGraph MCP Server\n",
      "  - 서버 데이터 추출: Perplexity MCP Zerver\n",
      "  - 서버 데이터 추출: Appwrite MCP Server\n",
      "  - 서버 데이터 추출: GitHub API MCP Server\n",
      "  - 서버 데이터 추출: Gitee MCP Server\n",
      "  - 서버 데이터 추출: Centinela Analytics Server\n",
      "  - 서버 데이터 추출: Airtable MCP\n",
      "  - 서버 데이터 추출: PapersWithCode Client\n",
      "  - 서버 데이터 추출: GitHub Mapper\n",
      "  - 서버 데이터 추출: Claude Custom Prompts\n",
      "  - 서버 데이터 추출: Windows Command Line MCP Server\n",
      "  - 서버 데이터 추출: NLTK Model Context Protocol Server\n",
      "  - 서버 데이터 추출: MCP Fetch\n",
      "  - 서버 데이터 추출: Weather MCP Tool\n",
      "  - 서버 데이터 추출: RAG Web Browser Server\n",
      "  - 서버 데이터 추출: Clickhouse MCP Server\n",
      "  - 서버 데이터 추출: Gmail Notes Server\n",
      "  - 서버 데이터 추출: Atlassian Confluence Integration\n",
      "  - 서버 데이터 추출: mcp-nixos\n",
      "페이지 13 완료: 20개 서버 추출 (누적: 260개)\n",
      "다음 요청까지 1.66초 대기 중...\n",
      "\n",
      "페이지 14 로드 중: https://smithery.ai/?q=is%3Adeployed&page=14\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Whimsical Diagram Creator\n",
      "  - 서버 데이터 추출: Code Runner MCP Server\n",
      "  - 서버 데이터 추출: 虚拟币价格查询服务\n",
      "  - 서버 데이터 추출: Calculator\n",
      "  - 서버 데이터 추출: Home Assistant MCP\n",
      "  - 서버 데이터 추출: Monday.com MCP - Typescript\n",
      "  - 서버 데이터 추출: LLMS.txt Explorer\n",
      "  - 서버 데이터 추출: doc-tools-mcp\n",
      "  - 서버 데이터 추출: URL Shortener MCP\n",
      "  - 서버 데이터 추출: Elasticsearch 7.x MCP Server\n",
      "  - 서버 데이터 추출: Audiense Demand\n",
      "  - 서버 데이터 추출: MotherDuck\n",
      "  - 서버 데이터 추출: Image Generator\n",
      "  - 서버 데이터 추출: Notion Integration\n",
      "  - 서버 데이터 추출: Dice Roller\n",
      "  - 서버 데이터 추출: Skrape MCP Server\n",
      "  - 서버 데이터 추출: Tenki\n",
      "  - 서버 데이터 추출: Scraper.is\n",
      "  - 서버 데이터 추출: JigsawStack AI Web Search\n",
      "  - 서버 데이터 추출: Jina Reader MCP Server\n",
      "페이지 14 완료: 20개 서버 추출 (누적: 280개)\n",
      "다음 요청까지 1.67초 대기 중...\n",
      "\n",
      "페이지 15 로드 중: https://smithery.ai/?q=is%3Adeployed&page=15\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Freshdesk Integration Server\n",
      "  - 서버 데이터 추출: Jina Reader MCP Server\n",
      "  - 서버 데이터 추출: Poker Win Calculator\n",
      "  - 서버 데이터 추출: Gemini Thinking 2.5 Pro\n",
      "  - 서버 데이터 추출: Plane MCP Server\n",
      "  - 서버 데이터 추출: Plane MCP Server\n",
      "  - 서버 데이터 추출: VirusTotal MCP Server\n",
      "  - 서버 데이터 추출: Coinmarket Server\n",
      "  - 서버 데이터 추출: Lilith Shell\n",
      "  - 서버 데이터 추출: PiAPI MCP Server\n",
      "  - 서버 데이터 추출: OpenAI Server\n",
      "  - 서버 데이터 추출: iOS Development Bridge Integration\n",
      "  - 서버 데이터 추출: DBT Semantic Layer Server\n",
      "  - 서버 데이터 추출: UML Diagram Generation Tool\n",
      "  - 서버 데이터 추출: Meilisearch MCP Server\n",
      "  - 서버 데이터 추출: Serper Search and Scrape\n",
      "  - 서버 데이터 추출: Datetime Formatting Server\n",
      "  - 서버 데이터 추출: Anki Integration Server\n",
      "  - 서버 데이터 추출: Solana Docs Server\n",
      "  - 서버 데이터 추출: LLM.txt MCP Server\n",
      "페이지 15 완료: 20개 서버 추출 (누적: 300개)\n",
      "다음 요청까지 2.12초 대기 중...\n",
      "\n",
      "페이지 16 로드 중: https://smithery.ai/?q=is%3Adeployed&page=16\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: LLM.txt MCP Server\n",
      "  - 서버 데이터 추출: Bear MCP Server\n",
      "  - 서버 데이터 추출: JigsawStack vOCR\n",
      "  - 서버 데이터 추출: Bitrefill MCP Server\n",
      "  - 서버 데이터 추출: 飞书MCP机器人\n",
      "  - 서버 데이터 추출: AWS Knowledge Base Retrieval\n",
      "  - 서버 데이터 추출: Serper Search and Scrape\n",
      "  - 서버 데이터 추출: Model Context Protocol Servers\n",
      "  - 서버 데이터 추출: Solana Trading Server\n",
      "  - 서버 데이터 추출: barnsworthburning\n",
      "  - 서버 데이터 추출: Brasil API\n",
      "  - 서버 데이터 추출: Desktop Commander\n",
      "  - 서버 데이터 추출: Web Content Server\n",
      "  - 서버 데이터 추출: RelevanceAI MCP Server\n",
      "  - 서버 데이터 추출: Figma API Integration Server\n",
      "  - 서버 데이터 추출: NASA MCP Server\n",
      "  - 서버 데이터 추출: TMDB Server\n",
      "  - 서버 데이터 추출: CCXT MCP Server\n",
      "  - 서버 데이터 추출: Prolog Execution and Querying\n",
      "  - 서버 데이터 추출: Gemini Docs Server\n",
      "페이지 16 완료: 20개 서버 추출 (누적: 320개)\n",
      "다음 요청까지 2.57초 대기 중...\n",
      "\n",
      "페이지 17 로드 중: https://smithery.ai/?q=is%3Adeployed&page=17\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: JigsawStack Translation\n",
      "  - 서버 데이터 추출: Gmail MCP Server\n",
      "  - 서버 데이터 추출: Node Omnibus Server\n",
      "  - 서버 데이터 추출: PocketBase MCP Server\n",
      "  - 서버 데이터 추출: LGTM\n",
      "  - 서버 데이터 추출: Pump.fun Data Fetch Tool\n",
      "  - 서버 데이터 추출: MCP Server Test\n",
      "  - 서버 데이터 추출: Hacker News\n",
      "  - 서버 데이터 추출: medRxiv MCP Server\n",
      "  - 서버 데이터 추출: Snowflake Database Access Server\n",
      "  - 서버 데이터 추출: Email sending\n",
      "  - 서버 데이터 추출: Mapbox Server\n",
      "  - 서버 데이터 추출: Pulse CN MCP Server\n",
      "  - 서버 데이터 추출: GitHub PR Comments Server\n",
      "  - 서버 데이터 추출: Scrappey MCP Server\n",
      "  - 서버 데이터 추출: GitHub Workflow Debugger\n",
      "  - 서버 데이터 추출: Kibela Integration Server\n",
      "  - 서버 데이터 추출: AniList MCP Server\n",
      "  - 서버 데이터 추출: Human Loop Server\n",
      "  - 서버 데이터 추출: HubSpot MCP Server\n",
      "페이지 17 완료: 20개 서버 추출 (누적: 340개)\n",
      "다음 요청까지 1.71초 대기 중...\n",
      "\n",
      "페이지 18 로드 중: https://smithery.ai/?q=is%3Adeployed&page=18\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: DynamoDB Server\n",
      "  - 서버 데이터 추출: HubSpot MCP Server\n",
      "  - 서버 데이터 추출: Google Chat MCP Server\n",
      "  - 서버 데이터 추출: Weather\n",
      "  - 서버 데이터 추출: Gmail MCP\n",
      "  - 서버 데이터 추출: Handwriting OCR\n",
      "  - 서버 데이터 추출: Fetch Server\n",
      "  - 서버 데이터 추출: Weather Tool\n",
      "  - 서버 데이터 추출: MultiversX MCP Server\n",
      "  - 서버 데이터 추출: Super Shell\n",
      "  - 서버 데이터 추출: Adb MySQL MCP Server\n",
      "  - 서버 데이터 추출: Kubernetes Server\n",
      "  - 서버 데이터 추출: Threat News\n",
      "  - 서버 데이터 추출: Text Editor MCP Server\n",
      "  - 서버 데이터 추출: Weather Server\n",
      "  - 서버 데이터 추출: Headless Gmail Server\n",
      "  - 서버 데이터 추출: Prometheus MCP Server\n",
      "  - 서버 데이터 추출: OpenAI Agents MCP Server\n",
      "  - 서버 데이터 추출: Dart MCP Server\n",
      "  - 서버 데이터 추출: WebSearch\n",
      "페이지 18 완료: 20개 서버 추출 (누적: 360개)\n",
      "다음 요청까지 1.31초 대기 중...\n",
      "\n",
      "페이지 19 로드 중: https://smithery.ai/?q=is%3Adeployed&page=19\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Flow RPC Server\n",
      "  - 서버 데이터 추출: FindMCP\n",
      "  - 서버 데이터 추출: Clickhouse and PostgreSQL with Neurelo Connect\n",
      "  - 서버 데이터 추출: Coding Prompt Engineer\n",
      "  - 서버 데이터 추출: OpenRPC MCP Server\n",
      "  - 서버 데이터 추출: Rijksmuseum Server\n",
      "  - 서버 데이터 추출: Python Documentation Server\n",
      "  - 서버 데이터 추출: Shodan MCP Server\n",
      "  - 서버 데이터 추출: BrowserCat MCP Server\n",
      "  - 서버 데이터 추출: XiYan MCP Server\n",
      "  - 서버 데이터 추출: Paylocity Data Fetcher\n",
      "  - 서버 데이터 추출: Trello Integration Server\n",
      "  - 서버 데이터 추출: YouTube MCP\n",
      "  - 서버 데이터 추출: Linkup Search\n",
      "  - 서버 데이터 추출: Figma MCP 服务器\n",
      "  - 서버 데이터 추출: HubSpot MCP\n",
      "  - 서버 데이터 추출: Kakao Map MCP server\n",
      "  - 서버 데이터 추출: Chronicle SecOps\n",
      "  - 서버 데이터 추출: Zig Server\n",
      "  - 서버 데이터 추출: Obsidian Integration Server\n",
      "페이지 19 완료: 20개 서버 추출 (누적: 380개)\n",
      "다음 요청까지 1.00초 대기 중...\n",
      "\n",
      "페이지 20 로드 중: https://smithery.ai/?q=is%3Adeployed&page=20\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: MCPet\n",
      "  - 서버 데이터 추출: Zig Server\n",
      "  - 서버 데이터 추출: Obsidian Integration Server\n",
      "  - 서버 데이터 추출: Atlassian Bitbucket Integration\n",
      "  - 서버 데이터 추출: FluentLab Funding Assistant\n",
      "  - 서버 데이터 추출: LLM Bridge\n",
      "  - 서버 데이터 추출: Daily Todo\n",
      "  - 서버 데이터 추출: Macrostrat API Server\n",
      "  - 서버 데이터 추출: GitHub API MCP Server\n",
      "  - 서버 데이터 추출: QRCode_MCP\n",
      "  - 서버 데이터 추출: Sketchup Integration\n",
      "  - 서버 데이터 추출: EMQX MCP Server\n",
      "  - 서버 데이터 추출: Ethereum RPC Server\n",
      "  - 서버 데이터 추출: Atom of Thoughts\n",
      "  - 서버 데이터 추출: Gaode Weather\n",
      "  - 서버 데이터 추출: Image Extractor\n",
      "  - 서버 데이터 추출: Chroma MCP Server\n",
      "  - 서버 데이터 추출: BrasilAPI MCP Server\n",
      "  - 서버 데이터 추출: Clickzetta Server\n",
      "  - 서버 데이터 추출: Beyond MCP Server\n",
      "페이지 20 완료: 20개 서버 추출 (누적: 400개)\n",
      "다음 요청까지 1.30초 대기 중...\n",
      "\n",
      "페이지 21 로드 중: https://smithery.ai/?q=is%3Adeployed&page=21\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Cal Server\n",
      "  - 서버 데이터 추출: Image Extractor\n",
      "  - 서버 데이터 추출: Amazon Selling Partner API Integration Server\n",
      "  - 서버 데이터 추출: Reference Servers\n",
      "  - 서버 데이터 추출: Singapore LTA MCP Server\n",
      "  - 서버 데이터 추출: Memory Box MCP Server\n",
      "  - 서버 데이터 추출: Clickzetta Server\n",
      "  - 서버 데이터 추출: Compress Files\n",
      "  - 서버 데이터 추출: Flightradar24 Server\n",
      "  - 서버 데이터 추출: GitLab Merge Request Integration\n",
      "  - 서버 데이터 추출: Logo MCP\n",
      "  - 서버 데이터 추출: Oura API Integration Server\n",
      "  - 서버 데이터 추출: SWAPI Server\n",
      "  - 서버 데이터 추출: Desktop Commander\n",
      "  - 서버 데이터 추출: Hive MCP Server\n",
      "  - 서버 데이터 추출: Twitter Interaction Server\n",
      "  - 서버 데이터 추출: OpenAI Agent Library\n",
      "  - 서버 데이터 추출: LinkedIn Digital Intelligence Server\n",
      "  - 서버 데이터 추출: Todoist MCP Server\n",
      "  - 서버 데이터 추출: Zotero MCP\n",
      "페이지 21 완료: 20개 서버 추출 (누적: 420개)\n",
      "다음 요청까지 2.94초 대기 중...\n",
      "\n",
      "페이지 22 로드 중: https://smithery.ai/?q=is%3Adeployed&page=22\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Brazilian Postal Code Server\n",
      "  - 서버 데이터 추출: Todoist MCP Server\n",
      "  - 서버 데이터 추출: Notion MCP\n",
      "  - 서버 데이터 추출: Ableton Live Integration\n",
      "  - 서버 데이터 추출: Code2Prompt MCP Server\n",
      "  - 서버 데이터 추출: Document Operations Server\n",
      "  - 서버 데이터 추출: Dida365 (TickTick) MCP Server\n",
      "  - 서버 데이터 추출: Horoscope MCP Server\n",
      "  - 서버 데이터 추출: TypeScript Definition Finder\n",
      "  - 서버 데이터 추출: Opik MCP Server\n",
      "  - 서버 데이터 추출: Transcription Tools\n",
      "  - 서버 데이터 추출: SCAST\n",
      "  - 서버 데이터 추출: Logaflow\n",
      "  - 서버 데이터 추출: Semantic Scholar Server\n",
      "  - 서버 데이터 추출: YouTube Transcription Server\n",
      "  - 서버 데이터 추출: Autumn MCP Server\n",
      "  - 서버 데이터 추출: ABAP-ADT-API MCP-Server\n",
      "  - 서버 데이터 추출: Xero MCP Server\n",
      "  - 서버 데이터 추출: Echo\n",
      "  - 서버 데이터 추출: Perplexity MCP Server\n",
      "페이지 22 완료: 20개 서버 추출 (누적: 440개)\n",
      "다음 요청까지 2.50초 대기 중...\n",
      "\n",
      "페이지 23 로드 중: https://smithery.ai/?q=is%3Adeployed&page=23\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: MCP Finder\n",
      "  - 서버 데이터 추출: Xero MCP Server\n",
      "  - 서버 데이터 추출: Logaflow\n",
      "  - 서버 데이터 추출: Autumn MCP Server\n",
      "  - 서버 데이터 추출: Brian Knows\n",
      "  - 서버 데이터 추출: GitHub API MCP Server\n",
      "  - 서버 데이터 추출: Weather Server\n",
      "  - 서버 데이터 추출: Linear Integration Server\n",
      "  - 서버 데이터 추출: Farcaster MCP Server\n",
      "  - 서버 데이터 추출: DuckDuckGo Search API\n",
      "  - 서버 데이터 추출: Jira Insights\n",
      "  - 서버 데이터 추출: Apple Tools\n",
      "  - 서버 데이터 추출: DiffuGen\n",
      "  - 서버 데이터 추출: Slack User MCP Server\n",
      "  - 서버 데이터 추출: Hevy Fitness API MCP Server\n",
      "  - 서버 데이터 추출: IP Geolocation Server\n",
      "  - 서버 데이터 추출: Keycloak\n",
      "  - 서버 데이터 추출: Solana Client\n",
      "  - 서버 데이터 추출: Cloudinary Server\n",
      "  - 서버 데이터 추출: Replicate FLUX Image Generator\n",
      "페이지 23 완료: 20개 서버 추출 (누적: 460개)\n",
      "다음 요청까지 2.46초 대기 중...\n",
      "\n",
      "페이지 24 로드 중: https://smithery.ai/?q=is%3Adeployed&page=24\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Think Tool Server\n",
      "  - 서버 데이터 추출: MCP Server\n",
      "  - 서버 데이터 추출: Apache Doris MCP Server\n",
      "  - 서버 데이터 추출: chinarailway MCP 服务端\n",
      "  - 서버 데이터 추출: Test MCP Service\n",
      "  - 서버 데이터 추출: AST Model Context Protocol Server\n",
      "  - 서버 데이터 추출: Refine Prompt\n",
      "  - 서버 데이터 추출: Simple MCP Server\n",
      "  - 서버 데이터 추출: Generate Image from HTML\n",
      "  - 서버 데이터 추출: Unreal Engine Plugin\n",
      "  - 서버 데이터 추출: NPM MCP Server\n",
      "  - 서버 데이터 추출: Code Review Server\n",
      "  - 서버 데이터 추출: eRegulations MCP Server\n",
      "  - 서버 데이터 추출: SourceSync.ai MCP Server\n",
      "  - 서버 데이터 추출: FTP Access Server\n",
      "  - 서버 데이터 추출: Palo Alto Networks MCP Server Suite\n",
      "  - 서버 데이터 추출: Outreach Today MCP\n",
      "  - 서버 데이터 추출: Create GitHub Repository Server\n",
      "  - 서버 데이터 추출: Desktop TXT File Manager\n",
      "  - 서버 데이터 추출: AWS SES Email Sender\n",
      "페이지 24 완료: 20개 서버 추출 (누적: 480개)\n",
      "다음 요청까지 1.62초 대기 중...\n",
      "\n",
      "페이지 25 로드 중: https://smithery.ai/?q=is%3Adeployed&page=25\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Math MCP Server\n",
      "  - 서버 데이터 추출: Prem AI MCP Server\n",
      "  - 서버 데이터 추출: Add Test\n",
      "  - 서버 데이터 추출: Superset Integration\n",
      "  - 서버 데이터 추출: CoinMarketCap MCP\n",
      "  - 서버 데이터 추출: Developer Name\n",
      "  - 서버 데이터 추출: Zerodha Integration\n",
      "  - 서버 데이터 추출: MCP GitHub Projects\n",
      "  - 서버 데이터 추출: YouTube MCP Server\n",
      "  - 서버 데이터 추출: Unsplash Server\n",
      "  - 서버 데이터 추출: Railway MCP Server\n",
      "  - 서버 데이터 추출: Flux Cloudflare MCP\n",
      "  - 서버 데이터 추출: MailPace MCP Server\n",
      "  - 서버 데이터 추출: Cloudflare Browser Rendering\n",
      "  - 서버 데이터 추출: Penumbra Blockchain\n",
      "  - 서버 데이터 추출: MCP Chain of Draft (CoD) Prompt Tool\n",
      "  - 서버 데이터 추출: My First MCP\n",
      "  - 서버 데이터 추출: JFrog MCP Server\n",
      "  - 서버 데이터 추출: Calculate Server\n",
      "  - 서버 데이터 추출: MCP Server\n",
      "페이지 25 완료: 20개 서버 추출 (누적: 500개)\n",
      "다음 요청까지 2.77초 대기 중...\n",
      "\n",
      "페이지 26 로드 중: https://smithery.ai/?q=is%3Adeployed&page=26\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Google Maps API Server\n",
      "  - 서버 데이터 추출: Coze Workflow\n",
      "  - 서버 데이터 추출: Adjust Reporting Server\n",
      "  - 서버 데이터 추출: HubSpot API Integration Server\n",
      "  - 서버 데이터 추출: FantasyPros API Server\n",
      "  - 서버 데이터 추출: PDF to Markdown Conversion Service\n",
      "  - 서버 데이터 추출: Exa MCP Server\n",
      "  - 서버 데이터 추출: Xiaohua\n",
      "  - 서버 데이터 추출: SorTage Gemini 2.5 Pro Thinking\n",
      "  - 서버 데이터 추출: GitHub MCP Server for Pera1\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: Browserbase MCP Server\n",
      "  - 서버 데이터 추출: testing\n",
      "  - 서버 데이터 추출: Map MCP Server\n",
      "  - 서버 데이터 추출: RSS Markdown Generator\n",
      "  - 서버 데이터 추출: mcp-server\n",
      "  - 서버 데이터 추출: Nmap Integration\n",
      "  - 서버 데이터 추출: Memos MCP 服务器\n",
      "  - 서버 데이터 추출: Olostep MCP Server\n",
      "  - 서버 데이터 추출: Volatility MCP Server\n",
      "페이지 26 완료: 20개 서버 추출 (누적: 520개)\n",
      "다음 요청까지 1.50초 대기 중...\n",
      "\n",
      "페이지 27 로드 중: https://smithery.ai/?q=is%3Adeployed&page=27\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Plausible Analytics Server\n",
      "  - 서버 데이터 추출: MCP Server for Continue\n",
      "  - 서버 데이터 추출: Asset Price MCP\n",
      "  - 서버 데이터 추출: Atlassian Jira Integration Server\n",
      "  - 서버 데이터 추출: HackMD MCP Server\n",
      "  - 서버 데이터 추출: Desktop TXT File Manager\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: Chaitin IP Intelligence\n",
      "  - 서버 데이터 추출: Rock Paper Scissors\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: EcoGo-AI\n",
      "  - 서버 데이터 추출: Grok AI MCP Server\n",
      "  - 서버 데이터 추출: Sample MCP Server\n",
      "  - 서버 데이터 추출: Car Listings\n",
      "  - 서버 데이터 추출: Pump.fun MCP Server\n",
      "  - 서버 데이터 추출: MCP Study\n",
      "  - 서버 데이터 추출: Dictionary Server\n",
      "  - 서버 데이터 추출: Wongames MCP\n",
      "  - 서버 데이터 추출: ALAPI MCP Server\n",
      "  - 서버 데이터 추출: Google Cloud Services Integration\n",
      "페이지 27 완료: 20개 서버 추출 (누적: 540개)\n",
      "다음 요청까지 2.39초 대기 중...\n",
      "\n",
      "페이지 28 로드 중: https://smithery.ai/?q=is%3Adeployed&page=28\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: FlightRadar\n",
      "  - 서버 데이터 추출: Raccoon AI MCP Server\n",
      "  - 서버 데이터 추출: Swift\n",
      "  - 서버 데이터 추출: Manifold Markets MCP Server\n",
      "  - 서버 데이터 추출: Gitee MCP Server\n",
      "  - 서버 데이터 추출: Modal MCP Toolbox\n",
      "  - 서버 데이터 추출: Flomo Notes Server\n",
      "  - 서버 데이터 추출: Sentry Issue Analyzer\n",
      "  - 서버 데이터 추출: CockroachDB MCP Server\n",
      "  - 서버 데이터 추출: Knowledge Graph Memory Server\n",
      "  - 서버 데이터 추출: Anki MCP Server\n",
      "  - 서버 데이터 추출: Boilerplate MCP Server\n",
      "  - 서버 데이터 추출: Omi MCP Server\n",
      "  - 서버 데이터 추출: Spotify Integration\n",
      "  - 서버 데이터 추출: Atris\n",
      "  - 서버 데이터 추출: Aiven MCP Server\n",
      "  - 서버 데이터 추출: MCP Server Example\n",
      "  - 서버 데이터 추출: MCP Server Test\n",
      "  - 서버 데이터 추출: Solana RPC Server\n",
      "  - 서버 데이터 추출: Alphavantage MCP Server\n",
      "페이지 28 완료: 20개 서버 추출 (누적: 560개)\n",
      "다음 요청까지 2.69초 대기 중...\n",
      "\n",
      "페이지 29 로드 중: https://smithery.ai/?q=is%3Adeployed&page=29\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Wait Timer Server\n",
      "  - 서버 데이터 추출: hh-jira-mcp-server\n",
      "  - 서버 데이터 추출: Cloudflare to GitHub Backup\n",
      "  - 서버 데이터 추출: AgentMail Toolkit\n",
      "  - 서버 데이터 추출: GitHub Trending\n",
      "  - 서버 데이터 추출: API.Market MCP Server (40 tools)\n",
      "  - 서버 데이터 추출: Pocket Connector\n",
      "  - 서버 데이터 추출: Bruno MCP Server\n",
      "  - 서버 데이터 추출: Neo4j Aura Database Manager\n",
      "  - 서버 데이터 추출: Chakra MCP Server\n",
      "  - 서버 데이터 추출: Tembo Cloud API\n",
      "  - 서버 데이터 추출: DICOM Model Context Protocol Server\n",
      "  - 서버 데이터 추출: DevHub CMS Integration\n",
      "  - 서버 데이터 추출: Safe MCP Server\n",
      "  - 서버 데이터 추출: Jupiter Swap API Server\n",
      "  - 서버 데이터 추출: Chargebee MCP Server\n",
      "  - 서버 데이터 추출: Azure Data Explorer Server\n",
      "  - 서버 데이터 추출: Tally API Server\n",
      "  - 서버 데이터 추출: Wikidata MCP Server\n",
      "  - 서버 데이터 추출: DexPaprika\n",
      "페이지 29 완료: 20개 서버 추출 (누적: 580개)\n",
      "다음 요청까지 2.87초 대기 중...\n",
      "\n",
      "페이지 30 로드 중: https://smithery.ai/?q=is%3Adeployed&page=30\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Votars MCP\n",
      "  - 서버 데이터 추출: IMDb Server\n",
      "  - 서버 데이터 추출: Fetch Server\n",
      "  - 서버 데이터 추출: ArcGIS Location Services\n",
      "  - 서버 데이터 추출: Marvel MCP Server\n",
      "  - 서버 데이터 추출: Clojure Linter\n",
      "  - 서버 데이터 추출: Q-Anon Posts/Drops Server\n",
      "  - 서버 데이터 추출: MCP Server Example\n",
      "  - 서버 데이터 추출: Parquet MCP Server\n",
      "  - 서버 데이터 추출: Microsoft 365 Bookings\n",
      "  - 서버 데이터 추출: Marginalia\n",
      "  - 서버 데이터 추출: API Security Tester\n",
      "  - 서버 데이터 추출: Think Tool Server\n",
      "  - 서버 데이터 추출: bioRxiv MCP Server\n",
      "  - 서버 데이터 추출: Microsoft 365 Core Server\n",
      "  - 서버 데이터 추출: Tradovate Tools\n",
      "  - 서버 데이터 추출: Remote MacOs Use\n",
      "  - 서버 데이터 추출: Exa MCP Server\n",
      "  - 서버 데이터 추출: Panintellegence API MCP Server\n",
      "  - 서버 데이터 추출: MCP Server Example\n",
      "페이지 30 완료: 20개 서버 추출 (누적: 600개)\n",
      "다음 요청까지 2.95초 대기 중...\n",
      "\n",
      "페이지 31 로드 중: https://smithery.ai/?q=is%3Adeployed&page=31\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: TinyPNG MCP Server\n",
      "  - 서버 데이터 추출: Giphy API Integration\n",
      "  - 서버 데이터 추출: YNAB Budget Assistant\n",
      "  - 서버 데이터 추출: Sharepoint\n",
      "  - 서버 데이터 추출: Veri5ight\n",
      "  - 서버 데이터 추출: Alpha Vantage MCP Server\n",
      "  - 서버 데이터 추출: Shodan MCP Server\n",
      "  - 서버 데이터 추출: FindMCP\n",
      "  - 서버 데이터 추출: SiYuan Note Server\n",
      "  - 서버 데이터 추출: Pica MCP Server\n",
      "  - 서버 데이터 추출: TinyPNG MCP Server\n",
      "  - 서버 데이터 추출: RapidAPI\n",
      "  - 서버 데이터 추출: APIMatic Validator\n",
      "  - 서버 데이터 추출: Yeoman Server\n",
      "  - 서버 데이터 추출: Unity MCP Template\n",
      "  - 서버 데이터 추출: LocalAPI MCP Server\n",
      "  - 서버 데이터 추출: mcp-test\n",
      "  - 서버 데이터 추출: Teste MCP Cedraz\n",
      "  - 서버 데이터 추출: DevDocs\n",
      "  - 서버 데이터 추출: Chain of Draft Server\n",
      "페이지 31 완료: 20개 서버 추출 (누적: 620개)\n",
      "다음 요청까지 2.52초 대기 중...\n",
      "\n",
      "페이지 32 로드 중: https://smithery.ai/?q=is%3Adeployed&page=32\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Apache JMeter Test Execution Server\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: Unified Narrative Operator\n",
      "  - 서버 데이터 추출: DingTalk AI Server\n",
      "  - 서버 데이터 추출: Octomind MCP Server\n",
      "  - 서버 데이터 추출: MCP Notifier\n",
      "  - 서버 데이터 추출: Unraid MCP Server\n",
      "  - 서버 데이터 추출: CISA M365\n",
      "  - 서버 데이터 추출: Verodat MCP Server\n",
      "  - 서버 데이터 추출: Palo Alto Device Server\n",
      "  - 서버 데이터 추출: Mesh Scanner\n",
      "  - 서버 데이터 추출: URL2SNAP\n",
      "  - 서버 데이터 추출: WildFly MCP Server\n",
      "  - 서버 데이터 추출: Gmail MCP (optional integration with Google Calendar)\n",
      "  - 서버 데이터 추출: Holaspirit\n",
      "  - 서버 데이터 추출: Omi Uber MCP Server\n",
      "  - 서버 데이터 추출: LlamaCloud\n",
      "  - 서버 데이터 추출: Git File Forensics\n",
      "  - 서버 데이터 추출: WireMCP\n",
      "  - 서버 데이터 추출: Palo Alto Policy Management Server\n",
      "페이지 32 완료: 20개 서버 추출 (누적: 640개)\n",
      "다음 요청까지 2.45초 대기 중...\n",
      "\n",
      "페이지 33 로드 중: https://smithery.ai/?q=is%3Adeployed&page=33\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: BICScan\n",
      "  - 서버 데이터 추출: Linode MCP Server\n",
      "  - 서버 데이터 추출: Claude Server\n",
      "  - 서버 데이터 추출: pure.md MCP server\n",
      "  - 서버 데이터 추출: Toolbox for LLM Enhancement\n",
      "  - 서버 데이터 추출: School MCP\n",
      "  - 서버 데이터 추출: Simple JavaScript REPL\n",
      "  - 서버 데이터 추출: R2 Gen\n",
      "  - 서버 데이터 추출: OpenVision\n",
      "  - 서버 데이터 추출: Armor Crypto\n",
      "  - 서버 데이터 추출: Sentry Server\n",
      "  - 서버 데이터 추출: Sui Tools\n",
      "  - 서버 데이터 추출: Emergency Medicare Management\n",
      "  - 서버 데이터 추출: Playwright Visual Test\n",
      "  - 서버 데이터 추출: Ramp MCP\n",
      "  - 서버 데이터 추출: MCP Multilspy\n",
      "  - 서버 데이터 추출: Targetprocess MCP Server\n",
      "  - 서버 데이터 추출: Eyevinn Open Source Cloud MCP Server\n",
      "  - 서버 데이터 추출: Honeycomb MCP Server\n",
      "  - 서버 데이터 추출: MercadoLibre MCP Server\n",
      "페이지 33 완료: 20개 서버 추출 (누적: 660개)\n",
      "다음 요청까지 1.63초 대기 중...\n",
      "\n",
      "페이지 34 로드 중: https://smithery.ai/?q=is%3Adeployed&page=34\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Time Server\n",
      "  - 서버 데이터 추출: Have I Been Pwned Integration Server\n",
      "  - 서버 데이터 추출: Figma MCP Python\n",
      "  - 서버 데이터 추출: Illumio MCP Server\n",
      "  - 서버 데이터 추출: Raygun Server\n",
      "  - 서버 데이터 추출: App Store Connect Server\n",
      "  - 서버 데이터 추출: YouTube Watch Later\n",
      "  - 서버 데이터 추출: Atlas Docs\n",
      "  - 서버 데이터 추출: Email Verification\n",
      "  - 서버 데이터 추출: Hyperspell\n",
      "  - 서버 데이터 추출: APISIX Model Context Protocol Server\n",
      "  - 서버 데이터 추출: Azure AI Agent Service\n",
      "  - 서버 데이터 추출: My Apple Remembers\n",
      "  - 서버 데이터 추출: Flux Schnell Image Generator\n",
      "  - 서버 데이터 추출: Framer Plugin Server\n",
      "  - 서버 데이터 추출: Nostr MCP Server\n",
      "  - 서버 데이터 추출: Calculate Server\n",
      "  - 서버 데이터 추출: Gemini Server\n",
      "  - 서버 데이터 추출: PubMed Server\n",
      "  - 서버 데이터 추출: NodeMCU Manager\n",
      "페이지 34 완료: 20개 서버 추출 (누적: 680개)\n",
      "다음 요청까지 1.32초 대기 중...\n",
      "\n",
      "페이지 35 로드 중: https://smithery.ai/?q=is%3Adeployed&page=35\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Atlassian Integration Server\n",
      "  - 서버 데이터 추출: mcp服务\n",
      "  - 서버 데이터 추출: Bluesky MCP Server\n",
      "  - 서버 데이터 추출: Iceberg Catalog\n",
      "  - 서버 데이터 추출: Fetch Server\n",
      "  - 서버 데이터 추출: Browserbase MCP Server\n",
      "  - 서버 데이터 추출: PlayFab Server\n",
      "  - 서버 데이터 추출: Two Truths and a Twist\n",
      "  - 서버 데이터 추출: Google Search Console Integration\n",
      "  - 서버 데이터 추출: Wait\n",
      "  - 서버 데이터 추출: MLflow Prompt Registry Server\n",
      "  - 서버 데이터 추출: Search Intent Analysis Service\n",
      "  - 서버 데이터 추출: Confluence MCP Server\n",
      "  - 서버 데이터 추출: Powerdrill MCP Server\n",
      "  - 서버 데이터 추출: IoTDB MCP Server\n",
      "  - 서버 데이터 추출: Calculator Server Example\n",
      "  - 서버 데이터 추출: LeetCode MCP Server\n",
      "  - 서버 데이터 추출: Webflow MCP Server\n",
      "  - 서버 데이터 추출: Task Manager\n",
      "  - 서버 데이터 추출: Document Management Server\n",
      "페이지 35 완료: 20개 서버 추출 (누적: 700개)\n",
      "다음 요청까지 1.04초 대기 중...\n",
      "\n",
      "페이지 36 로드 중: https://smithery.ai/?q=is%3Adeployed&page=36\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Practices MCP Server\n",
      "  - 서버 데이터 추출: GitHub API MCP Server\n",
      "  - 서버 데이터 추출: WebAgentQA\n",
      "  - 서버 데이터 추출: Memory Bank\n",
      "  - 서버 데이터 추출: Memento\n",
      "  - 서버 데이터 추출: Flux Schnell\n",
      "  - 서버 데이터 추출: OneSearch\n",
      "  - 서버 데이터 추출: Frontapp Integration Server\n",
      "  - 서버 데이터 추출: Generate Image from HTML\n",
      "  - 서버 데이터 추출: Supabase MCP Server (used by Deploya.dev)\n",
      "  - 서버 데이터 추출: Memory Bank Server\n",
      "  - 서버 데이터 추출: MySQL Server\n",
      "  - 서버 데이터 추출: Clear Thought MCP Server\n",
      "  - 서버 데이터 추출: Redis Server\n",
      "  - 서버 데이터 추출: Supabase MCP Server\n",
      "  - 서버 데이터 추출: BigQuery\n",
      "  - 서버 데이터 추출: Selenium WebDriver Automation\n",
      "  - 서버 데이터 추출: Elasticsearch Server\n",
      "  - 서버 데이터 추출: Browser Use (used by Deploya.dev)\n",
      "  - 서버 데이터 추출: Figma MCP Python\n",
      "페이지 36 완료: 20개 서버 추출 (누적: 720개)\n",
      "다음 요청까지 2.33초 대기 중...\n",
      "\n",
      "페이지 37 로드 중: https://smithery.ai/?q=is%3Adeployed&page=37\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Supabase MCP Server\n",
      "  - 서버 데이터 추출: Netlify MCP Server\n",
      "  - 서버 데이터 추출: Supabase MCP Server\n",
      "  - 서버 데이터 추출: MCP Proxy\n",
      "  - 서버 데이터 추출: Perplexity Server\n",
      "  - 서버 데이터 추출: Playwright Server\n",
      "  - 서버 데이터 추출: Supabase Notes\n",
      "  - 서버 데이터 추출: Data Visualization Server\n",
      "  - 서버 데이터 추출: HR Response Server\n",
      "  - 서버 데이터 추출: WebMCP\n",
      "  - 서버 데이터 추출: MetaMCP Server\n",
      "  - 서버 데이터 추출: OpenAPI MCP Server\n",
      "  - 서버 데이터 추출: Outline Document Search Server\n",
      "  - 서버 데이터 추출: RAG Documentation Server\n",
      "  - 서버 데이터 추출: GemSuite\n",
      "  - 서버 데이터 추출: Email sending (used by Deploya.dev)\n",
      "  - 서버 데이터 추출: RAG Documentation\n",
      "  - 서버 데이터 추출: 时间查询服务器\n",
      "  - 서버 데이터 추출: Redmine\n",
      "  - 서버 데이터 추출: CouchDB MCP Server\n",
      "페이지 37 완료: 20개 서버 추출 (누적: 740개)\n",
      "다음 요청까지 2.45초 대기 중...\n",
      "\n",
      "페이지 38 로드 중: https://smithery.ai/?q=is%3Adeployed&page=38\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Yet Another Linear MCP Server\n",
      "  - 서버 데이터 추출: Vega-Lite Data Visualization Server\n",
      "  - 서버 데이터 추출: Nostr MCP Server\n",
      "  - 서버 데이터 추출: Filesystem Server\n",
      "  - 서버 데이터 추출: Make MCP Server\n",
      "  - 서버 데이터 추출: Filesystem Server\n",
      "  - 서버 데이터 추출: GitHub Integration Server\n",
      "  - 서버 데이터 추출: QUANT AGI Tool Development\n",
      "  - 서버 데이터 추출: NOAA Tides and Currents\n",
      "  - 서버 데이터 추출: Filesystem MCP Server\n",
      "  - 서버 데이터 추출: Airtable Integration Tool\n",
      "  - 서버 데이터 추출: StarRocks MCP Server\n",
      "  - 서버 데이터 추출: OpenAI MCP Server\n",
      "  - 서버 데이터 추출: Echo Map\n",
      "  - 서버 데이터 추출: MCP for Evolution API for WhatsApp Automation\n",
      "  - 서버 데이터 추출: OracleDB MCP Server\n",
      "  - 서버 데이터 추출: Simple Timeserver\n",
      "  - 서버 데이터 추출: Scholarly Search\n",
      "  - 서버 데이터 추출: My MCP Project\n",
      "  - 서버 데이터 추출: SEO Automation and Optimization\n",
      "페이지 38 완료: 20개 서버 추출 (누적: 760개)\n",
      "다음 요청까지 1.40초 대기 중...\n",
      "\n",
      "페이지 39 로드 중: https://smithery.ai/?q=is%3Adeployed&page=39\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Clockify Integration\n",
      "  - 서버 데이터 추출: Model Context Protocol Server for Smithery\n",
      "  - 서버 데이터 추출: myAI Memory Sync\n",
      "  - 서버 데이터 추출: Place ID Server\n",
      "  - 서버 데이터 추출: GitLab Communication Server\n",
      "  - 서버 데이터 추출: YepCode MCP Server\n",
      "  - 서버 데이터 추출: FigmaMind\n",
      "  - 서버 데이터 추출: Weather HTTP Server\n",
      "  - 서버 데이터 추출: Ads Manager\n",
      "  - 서버 데이터 추출: Perplexity Search Golang\n",
      "  - 서버 데이터 추출: GraphQL API Integration\n",
      "  - 서버 데이터 추출: FastDomainCheck\n",
      "  - 서버 데이터 추출: DataForSEO API Server\n",
      "  - 서버 데이터 추출: G Suite Integration\n",
      "  - 서버 데이터 추출: MCP-framework\n",
      "  - 서버 데이터 추출: PayPal MCP Server\n",
      "  - 서버 데이터 추출: MongoDB MCP Server\n",
      "  - 서버 데이터 추출: Dropbox Integration Server\n",
      "  - 서버 데이터 추출: Crypto Price & Market Analysis Server\n",
      "  - 서버 데이터 추출: Unity MCP Server\n",
      "페이지 39 완료: 20개 서버 추출 (누적: 780개)\n",
      "다음 요청까지 1.83초 대기 중...\n",
      "\n",
      "페이지 40 로드 중: https://smithery.ai/?q=is%3Adeployed&page=40\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Airbnb Search Server\n",
      "  - 서버 데이터 추출: Govee MCP Server\n",
      "  - 서버 데이터 추출: Perplexity-researcher-mcp\n",
      "  - 서버 데이터 추출: claudeus-wp-mcp\n",
      "  - 서버 데이터 추출: Autonomous Coder Agent\n",
      "  - 서버 데이터 추출: mcp-server-gitlab\n",
      "  - 서버 데이터 추출: Weaviate MCP Server\n",
      "  - 서버 데이터 추출: Twitter MCP Client\n",
      "  - 서버 데이터 추출: Kagi Search\n",
      "  - 서버 데이터 추출: Grokart\n",
      "  - 서버 데이터 추출: Memory Service\n",
      "  - 서버 데이터 추출: Bing Search\n",
      "  - 서버 데이터 추출: Twikit Twitter Search\n",
      "  - 서버 데이터 추출: Overseerr MCP Server\n",
      "  - 서버 데이터 추출: Unsplash Smart MCP Server\n",
      "  - 서버 데이터 추출: Rootly MCP Server\n",
      "  - 서버 데이터 추출: MCP Test Server\n",
      "  - 서버 데이터 추출: 时间服务器\n",
      "  - 서버 데이터 추출: GraphQL MCP Toolkit\n",
      "  - 서버 데이터 추출: API to MCP Tools\n",
      "페이지 40 완료: 20개 서버 추출 (누적: 800개)\n",
      "다음 요청까지 1.56초 대기 중...\n",
      "\n",
      "페이지 41 로드 중: https://smithery.ai/?q=is%3Adeployed&page=41\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Entity Identification\n",
      "  - 서버 데이터 추출: Serp API Server\n",
      "  - 서버 데이터 추출: Apifox MCP Server\n",
      "  - 서버 데이터 추출: Centralized Control Server\n",
      "  - 서버 데이터 추출: Tavily Search\n",
      "  - 서버 데이터 추출: lightRAG\n",
      "  - 서버 데이터 추출: SEO Automation and Optimization\n",
      "  - 서버 데이터 추출: WordPress MCP\n",
      "  - 서버 데이터 추출: Discord MCP Server\n",
      "  - 서버 데이터 추출: ServeMyAPI\n",
      "  - 서버 데이터 추출: Readwise MCP Server\n",
      "  - 서버 데이터 추출: FileSystem Tool\n",
      "  - 서버 데이터 추출: PluggedinMCP Server\n",
      "  - 서버 데이터 추출: Tradovate\n",
      "  - 서버 데이터 추출: Memory Server with Qdrant Persistence\n",
      "  - 서버 데이터 추출: ITSM Integration Platform\n",
      "  - 서버 데이터 추출: Cybersecurity-focused MCP Server\n",
      "  - 서버 데이터 추출: SearXNG Search Connector\n",
      "  - 서버 데이터 추출: Website Information MCP Server\n",
      "  - 서버 데이터 추출: LSD MCP server\n",
      "페이지 41 완료: 20개 서버 추출 (누적: 820개)\n",
      "다음 요청까지 1.45초 대기 중...\n",
      "\n",
      "페이지 42 로드 중: https://smithery.ai/?q=is%3Adeployed&page=42\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Automate GUI Testing and Control\n",
      "  - 서버 데이터 추출: Atlassian Integration\n",
      "  - 서버 데이터 추출: Opik MCP Server\n",
      "  - 서버 데이터 추출: Clockify Time Tracker\n",
      "  - 서버 데이터 추출: Paradex Server\n",
      "  - 서버 데이터 추출: Canvas Server\n",
      "  - 서버 데이터 추출: Airtable Integration Tool\n",
      "  - 서버 데이터 추출: Ethereum Tools for Claude\n",
      "  - 서버 데이터 추출: Tool Chainer\n",
      "  - 서버 데이터 추출: Azure DevOps Integration Server\n",
      "  - 서버 데이터 추출: Documentation MCP Server\n",
      "  - 서버 데이터 추출: Say Follow Me\n",
      "  - 서버 데이터 추출: Home Assistant MCP Server\n",
      "  - 서버 데이터 추출: DingTalk Message Connector\n",
      "  - 서버 데이터 추출: USGS Earthquake Data\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: Hosted MCP\n",
      "  - 서버 데이터 추출: Miro Extension\n",
      "  - 서버 데이터 추출: MCP Server Template for Cursor IDE\n",
      "  - 서버 데이터 추출: VLM Run MCP Server\n",
      "페이지 42 완료: 20개 서버 추출 (누적: 840개)\n",
      "다음 요청까지 2.29초 대기 중...\n",
      "\n",
      "페이지 43 로드 중: https://smithery.ai/?q=is%3Adeployed&page=43\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Pinata MCP\n",
      "  - 서버 데이터 추출: AIClaude\n",
      "  - 서버 데이터 추출: SkySQL Integration\n",
      "  - 서버 데이터 추출: Weather MCP Server\n",
      "  - 서버 데이터 추출: Perplexity MCP Server\n",
      "  - 서버 데이터 추출: Titan Memory Server\n",
      "  - 서버 데이터 추출: Source Map Parser\n",
      "  - 서버 데이터 추출: wcgw\n",
      "  - 서버 데이터 추출: Glif MCP Server\n",
      "  - 서버 데이터 추출: Azure DevOps Integration Server\n",
      "  - 서버 데이터 추출: Heimdall\n",
      "  - 서버 데이터 추출: Binance Trading Server\n",
      "  - 서버 데이터 추출: Didlogic MCP Server\n",
      "  - 서버 데이터 추출: MCP Server\n",
      "  - 서버 데이터 추출: Supabase Server\n",
      "  - 서버 데이터 추출: MarkItDown MCP Server\n",
      "  - 서버 데이터 추출: PipeRun MCP\n",
      "  - 서버 데이터 추출: Sleep Tool\n",
      "  - 서버 데이터 추출: Android ADB Server\n",
      "  - 서버 데이터 추출: Local Network MCP\n",
      "페이지 43 완료: 20개 서버 추출 (누적: 860개)\n",
      "다음 요청까지 1.77초 대기 중...\n",
      "\n",
      "페이지 44 로드 중: https://smithery.ai/?q=is%3Adeployed&page=44\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: MCP Forge\n",
      "  - 서버 데이터 추출: UNHCR Demographics Server\n",
      "  - 서버 데이터 추출: PubTator Server\n",
      "  - 서버 데이터 추출: Deep Research\n",
      "  - 서버 데이터 추출: Hosted MCP\n",
      "  - 서버 데이터 추출: OpenRouter Multimodal Server\n",
      "  - 서버 데이터 추출: G Suite Integration\n",
      "  - 서버 데이터 추출: SingleStore MCP Server\n",
      "  - 서버 데이터 추출: UML Model Context Protocol\n",
      "  - 서버 데이터 추출: Stripe Server\n",
      "  - 서버 데이터 추출: MCP Development Framework\n",
      "  - 서버 데이터 추출: DevEnvInfoServer\n",
      "  - 서버 데이터 추출: MPC Server\n",
      "  - 서버 데이터 추출: MySQL MCP Server\n",
      "  - 서버 데이터 추출: Kubernetes MCP Server\n",
      "  - 서버 데이터 추출: MCP CodeCommit Integration\n",
      "  - 서버 데이터 추출: Azure DevOps Integration Server\n",
      "  - 서버 데이터 추출: SearXNG MCP Server\n",
      "  - 서버 데이터 추출: Sefaria Jewish Library\n",
      "  - 서버 데이터 추출: Calendar AutoAuth Server\n",
      "페이지 44 완료: 20개 서버 추출 (누적: 880개)\n",
      "다음 요청까지 1.61초 대기 중...\n",
      "\n",
      "페이지 45 로드 중: https://smithery.ai/?q=is%3Adeployed&page=45\n",
      "발견된 서버 카드: 26개\n",
      "  - 서버 데이터 추출: Ghost MCP Server\n",
      "  - 서버 데이터 추출: Florence-2\n",
      "  - 서버 데이터 추출: Slack Model Context Protocol Server\n",
      "  - 서버 데이터 추출: SearxNG Server\n",
      "  - 서버 데이터 추출: OCR Integration Server\n",
      "  - 서버 데이터 추출: SwitchBot Server\n",
      "  - 서버 데이터 추출: Shopify MCP Server\n",
      "  - 서버 데이터 추출: POC MCP Server\n",
      "  - 서버 데이터 추출: Gemini MCP\n",
      "  - 서버 데이터 추출: Descope MCP Server\n",
      "  - 서버 데이터 추출: mcp2mqtt\n",
      "  - 서버 데이터 추출: MongoDB MCP Server\n",
      "페이지 45 완료: 12개 서버 추출 (누적: 892개)\n",
      "데이터 저장 완료: smithery_servers.csv (892개 서버)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>usage_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sequential Thinking</td>\n",
       "      <td>An MCP server implementation that provides a t...</td>\n",
       "      <td>https://smithery.ai/server/@smithery-ai/server...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>681.30k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop Commander</td>\n",
       "      <td>Execute terminal commands and manage files wit...</td>\n",
       "      <td>https://smithery.ai/server/@wonderwhy-er/deskt...</td>\n",
       "      <td>Local</td>\n",
       "      <td>331.87k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Github</td>\n",
       "      <td>Access the GitHub API, enabling file operation...</td>\n",
       "      <td>https://smithery.ai/server/@smithery-ai/github</td>\n",
       "      <td>Remote</td>\n",
       "      <td>229.15k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think Tool Server</td>\n",
       "      <td>Enhance your AI's reasoning capabilities with ...</td>\n",
       "      <td>https://smithery.ai/server/@PhillipRt/think-mc...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>199.28k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brave Search</td>\n",
       "      <td>Integrate web search and local search capabili...</td>\n",
       "      <td>https://smithery.ai/server/@smithery-ai/brave-...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>155.66k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                        description  \\\n",
       "0  Sequential Thinking  An MCP server implementation that provides a t...   \n",
       "1    Desktop Commander  Execute terminal commands and manage files wit...   \n",
       "2               Github  Access the GitHub API, enabling file operation...   \n",
       "3    Think Tool Server  Enhance your AI's reasoning capabilities with ...   \n",
       "4         Brave Search  Integrate web search and local search capabili...   \n",
       "\n",
       "                                                 url    type usage_count  \n",
       "0  https://smithery.ai/server/@smithery-ai/server...  Remote     681.30k  \n",
       "1  https://smithery.ai/server/@wonderwhy-er/deskt...   Local     331.87k  \n",
       "2     https://smithery.ai/server/@smithery-ai/github  Remote     229.15k  \n",
       "3  https://smithery.ai/server/@PhillipRt/think-mc...  Remote     199.28k  \n",
       "4  https://smithery.ai/server/@smithery-ai/brave-...  Remote     155.66k  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install requests beautifulsoup4 pandas tqdm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from tqdm.notebook import tqdm  # 주피터 노트북용 진행 표시줄\n",
    "\n",
    "class SmitherySimpleCrawler:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Smithery.ai crawler\n",
    "        \"\"\"\n",
    "        # 쿠키와 헤더 설정\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Referer': 'https://smithery.ai/',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # 모든 서버 데이터를 저장할 리스트\n",
    "        self.all_data = []\n",
    "    \n",
    "    def random_sleep(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"\n",
    "        Sleep for a random amount of time\n",
    "        \n",
    "        Args:\n",
    "            min_seconds (float): Minimum sleep time in seconds\n",
    "            max_seconds (float): Maximum sleep time in seconds\n",
    "        \"\"\"\n",
    "        sleep_time = random.uniform(min_seconds, max_seconds)\n",
    "        print(f\"다음 요청까지 {sleep_time:.2f}초 대기 중...\")\n",
    "        time.sleep(sleep_time)\n",
    "    \n",
    "    def get_page(self, page_number):\n",
    "        \"\"\"\n",
    "        Get the HTML content of a specific page\n",
    "        \n",
    "        Args:\n",
    "            page_number (int): Page number to fetch\n",
    "        \n",
    "        Returns:\n",
    "            BeautifulSoup: Parsed HTML content\n",
    "        \"\"\"\n",
    "        url = f\"https://smithery.ai/?q=is%3Adeployed&page={page_number}\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n페이지 {page_number} 로드 중: {url}\")\n",
    "            response = self.session.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return BeautifulSoup(response.text, 'html.parser')\n",
    "            else:\n",
    "                print(f\"Error: HTTP {response.status_code} - {url}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"페이지 로드 중 오류 발생: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_server_data(self, soup):\n",
    "        \"\"\"\n",
    "        Extract server data from a BeautifulSoup object\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML content\n",
    "        \n",
    "        Returns:\n",
    "            list: List of dictionaries containing server data\n",
    "        \"\"\"\n",
    "        servers_data = []\n",
    "        \n",
    "        if soup is None:\n",
    "            return servers_data\n",
    "        \n",
    "        try:\n",
    "            # 카드를 찾기 위한 다양한 선택자 시도\n",
    "            server_cards = (\n",
    "                soup.select('.card') or \n",
    "                soup.select('[class*=\"card\"]') or \n",
    "                soup.select('a[href*=\"/smithery-ai/\"]') or\n",
    "                soup.select('a[href*=\"smithery.ai\"]') or\n",
    "                soup.select('main > div > div > div > div > a') or\n",
    "                # 추가 선택자 - 가능한 모든 서버 카드 포함\n",
    "                soup.select('div > a[href]')\n",
    "            )\n",
    "            \n",
    "            print(f\"발견된 서버 카드: {len(server_cards)}개\")\n",
    "            \n",
    "            for card in server_cards:\n",
    "                server = {}\n",
    "                \n",
    "                # 서버 이름 추출 시도\n",
    "                name_element = (\n",
    "                    card.select_one('h2') or \n",
    "                    card.select_one('h3') or \n",
    "                    card.select_one('h3 > span') or\n",
    "                    card.select_one('div > h3') or\n",
    "                    card.select_one('div > h3 > span') or\n",
    "                    card.select_one('span[class*=\"title\"]') or\n",
    "                    card.select_one('div[class*=\"title\"]')\n",
    "                )\n",
    "                \n",
    "                if name_element:\n",
    "                    server['name'] = name_element.get_text().strip()\n",
    "                \n",
    "                # 서버 핸들 추출 (@로 시작하는 텍스트)\n",
    "                texts = card.get_text().split('\\n')\n",
    "                for text in texts:\n",
    "                    text = text.strip()\n",
    "                    if text.startswith('@'):\n",
    "                        server['handle'] = text\n",
    "                        break\n",
    "                \n",
    "                # 설명 추출\n",
    "                desc_element = (\n",
    "                    card.select_one('p') or \n",
    "                    card.select_one('div > p') or\n",
    "                    card.select_one('div[class*=\"description\"]')\n",
    "                )\n",
    "                \n",
    "                if desc_element and not desc_element.get_text().strip().startswith('@'):\n",
    "                    server['description'] = desc_element.get_text().strip()\n",
    "                else:\n",
    "                    # 설명을 찾을 수 없는 경우 모든 텍스트 블록을 검사\n",
    "                    for p in card.select('p'):\n",
    "                        text = p.get_text().strip()\n",
    "                        if text and not text.startswith('@'):\n",
    "                            server['description'] = text\n",
    "                            break\n",
    "                \n",
    "                # URL 추출\n",
    "                if card.name == 'a' and card.has_attr('href'):\n",
    "                    url = card['href']\n",
    "                    if not url.startswith('http'):\n",
    "                        url = f\"https://smithery.ai{url}\"\n",
    "                    server['url'] = url\n",
    "                else:\n",
    "                    url_element = card.select_one('a')\n",
    "                    if url_element and url_element.has_attr('href'):\n",
    "                        url = url_element['href']\n",
    "                        if not url.startswith('http'):\n",
    "                            url = f\"https://smithery.ai{url}\"\n",
    "                        server['url'] = url\n",
    "                \n",
    "                # 유형 및 사용량 추출\n",
    "                for span in card.select('span'):\n",
    "                    text = span.get_text().strip()\n",
    "                    if text in ['Remote', 'Local']:\n",
    "                        server['type'] = text\n",
    "                    elif text.endswith('k') and any(c.isdigit() for c in text):\n",
    "                        server['usage_count'] = text\n",
    "                \n",
    "                # 이름이나 핸들이 있는 서버만 추가\n",
    "                if server.get('name') or server.get('handle'):\n",
    "                    # URL이 실제 서버와 관련된 것인지 확인 (필터링)\n",
    "                    if server.get('url') and ('/smithery-ai/' in server.get('url') or '/server/' in server.get('url')):\n",
    "                        servers_data.append(server)\n",
    "                        print(f\"  - 서버 데이터 추출: {server.get('name', server.get('handle', '알 수 없음'))}\")\n",
    "            \n",
    "            return servers_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"서버 데이터 추출 중 오류 발생: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return servers_data\n",
    "    \n",
    "    def extract_server_details(self, url):\n",
    "        \"\"\"\n",
    "        Extract additional details from a server's page\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the server's page\n",
    "        \n",
    "        Returns:\n",
    "            dict: Additional details about the server\n",
    "        \"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        try:\n",
    "            self.random_sleep(0.5, 1.5)  # 짧은 대기 시간\n",
    "            \n",
    "            response = self.session.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"  - 서버 상세 정보 로드 실패: HTTP {response.status_code}\")\n",
    "                return details\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # 라이선스 정보 추출\n",
    "            license_elements = soup.find_all(string=re.compile('License', re.I))\n",
    "            for element in license_elements:\n",
    "                parent = element.parent\n",
    "                if parent and parent.name in ['dt', 'h3', 'h4', 'strong', 'b', 'span']:\n",
    "                    sibling = parent.find_next_sibling()\n",
    "                    if sibling:\n",
    "                        details['license'] = sibling.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            # 출시일 추출\n",
    "            publish_elements = soup.find_all(string=re.compile('Published', re.I))\n",
    "            for element in publish_elements:\n",
    "                parent = element.parent\n",
    "                if parent and parent.name in ['dt', 'h3', 'h4', 'strong', 'b', 'span']:\n",
    "                    sibling = parent.find_next_sibling()\n",
    "                    if sibling:\n",
    "                        details['published_date'] = sibling.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            # 설치 명령어 추출\n",
    "            install_elements = soup.find_all(string=re.compile('Installation|Install', re.I))\n",
    "            for element in install_elements:\n",
    "                parent = element.parent\n",
    "                if parent:\n",
    "                    code_block = parent.find_next('code') or parent.find_next('pre')\n",
    "                    if code_block:\n",
    "                        details['installation'] = code_block.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            return details\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - 서버 상세 정보 추출 중 오류 발생: {str(e)}\")\n",
    "            return details\n",
    "    \n",
    "    def crawl_pages(self, start_page=1, end_page=45, get_details=False):\n",
    "        \"\"\"\n",
    "        Crawl a range of pages from Smithery.ai\n",
    "        \n",
    "        Args:\n",
    "            start_page (int): Page to start crawling from\n",
    "            end_page (int): Page to stop crawling at\n",
    "            get_details (bool): Whether to fetch additional details from each server's page\n",
    "        \n",
    "        Returns:\n",
    "            list: All scraped data\n",
    "        \"\"\"\n",
    "        # 결과를 초기화\n",
    "        self.all_data = []\n",
    "        \n",
    "        # tqdm으로 진행 상황 표시\n",
    "        for page_number in tqdm(range(start_page, end_page + 1), desc=\"페이지 크롤링\"):\n",
    "            # HTML 콘텐츠 가져오기\n",
    "            soup = self.get_page(page_number)\n",
    "            \n",
    "            # 서버 데이터 추출\n",
    "            page_data = self.extract_server_data(soup)\n",
    "            \n",
    "            # 상세 정보 추출 (선택 사항)\n",
    "            if get_details and page_data:\n",
    "                print(\"서버 상세 정보 추출 중...\")\n",
    "                for server in tqdm(page_data, desc=\"서버 상세 정보\"):\n",
    "                    if 'url' in server:\n",
    "                        details = self.extract_server_details(server['url'])\n",
    "                        server.update(details)\n",
    "            \n",
    "            # 결과 저장\n",
    "            self.all_data.extend(page_data)\n",
    "            \n",
    "            print(f\"페이지 {page_number} 완료: {len(page_data)}개 서버 추출 (누적: {len(self.all_data)}개)\")\n",
    "            \n",
    "            # 다음 페이지 로드 전에 대기\n",
    "            if page_number < end_page:\n",
    "                self.random_sleep()\n",
    "        \n",
    "        return self.all_data\n",
    "    \n",
    "    def save_to_csv(self, filename=\"smithery_servers.csv\"):\n",
    "        \"\"\"\n",
    "        Save the scraped data to a CSV file\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Name of the CSV file to save\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the scraped data\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.all_data)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"데이터 저장 완료: {filename} ({len(self.all_data)}개 서버)\")\n",
    "        return df\n",
    "\n",
    "# 실행 설정\n",
    "START_PAGE = 1  # 시작 페이지\n",
    "END_PAGE = 5    # 종료 페이지 (테스트용으로 낮게 설정)\n",
    "GET_DETAILS = False  # 상세 정보 추출 여부\n",
    "OUTPUT_FILE = \"smithery_servers.csv\"  # 결과 파일명\n",
    "\n",
    "# 크롤러 실행 함수\n",
    "def run_crawler(start_page=START_PAGE, end_page=END_PAGE, get_details=GET_DETAILS, output_file=OUTPUT_FILE):\n",
    "    \"\"\"\n",
    "    Smithery.ai 크롤러를 실행하고 결과를 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        start_page (int): 시작 페이지\n",
    "        end_page (int): 종료 페이지\n",
    "        get_details (bool): 상세 정보 추출 여부\n",
    "        output_file (str): 결과 파일명\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 크롤링 결과\n",
    "    \"\"\"\n",
    "    # 크롤러 초기화\n",
    "    crawler = SmitherySimpleCrawler()\n",
    "    \n",
    "    # 크롤링 수행\n",
    "    crawler.crawl_pages(start_page=start_page, end_page=end_page, get_details=get_details)\n",
    "    \n",
    "    # 결과 저장 및 반환\n",
    "    df = crawler.save_to_csv(output_file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 아래 주석을 제거하고 실행하세요\n",
    "df = run_crawler(start_page=1, end_page=45)\n",
    "df.head()  # 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== 검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' 크롤링 시작 ===\n",
      "\n",
      "\n",
      "검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' - 페이지 1 로드 중: https://smithery.ai/?q=Explore%20servers%20that%20provide%20advanced%20tools%20for%20tracking%20and%20analyzing%20cryptocurrency%20transactions%2C%20liquidity%20pools%2C%20and%20financial%20market%20data%2C%20including%20integrations%20with%20DeFi%20platforms%20and%20real-time%20financial%20metrics.&page=1\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Resources\n",
      "  - 서버 데이터 추출: Crypto Price & Market Analysis Server\n",
      "  - 서버 데이터 추출: Lunchmoney MCP Server\n",
      "  - 서버 데이터 추출: MCP Server Starter\n",
      "  - 서버 데이터 추출: Alpha Vantage Stock Server\n",
      "  - 서버 데이터 추출: Coin MCP Server\n",
      "  - 서버 데이터 추출: Helius\n",
      "  - 서버 데이터 추출: Algorand MCP Server\n",
      "  - 서버 데이터 추출: Etherscan Tools\n",
      "  - 서버 데이터 추출: Financial Data Server\n",
      "  - 서버 데이터 추출: 虚拟币价格查询服务\n",
      "  - 서버 데이터 추출: Coinmarket Server\n",
      "  - 서버 데이터 추출: CCXT MCP Server\n",
      "  - 서버 데이터 추출: Solana Trading Server\n",
      "  - 서버 데이터 추출: Pump.fun Data Fetch Tool\n",
      "  - 서버 데이터 추출: Beyond MCP Server\n",
      "  - 서버 데이터 추출: CoinMarketCap MCP\n",
      "  - 서버 데이터 추출: Penumbra Blockchain\n",
      "  - 서버 데이터 추출: DexPaprika\n",
      "  - 서버 데이터 추출: Pump.fun MCP Server\n",
      "  - 서버 데이터 추출: Tradovate Tools\n",
      "페이지 1 완료: 21개 서버 추출\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a03e22fbbf04970b64e27a76666344b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 요청까지 2.35초 대기 중...\n",
      "\n",
      "검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' - 페이지 2 로드 중: https://smithery.ai/?q=Explore%20servers%20that%20provide%20advanced%20tools%20for%20tracking%20and%20analyzing%20cryptocurrency%20transactions%2C%20liquidity%20pools%2C%20and%20financial%20market%20data%2C%20including%20integrations%20with%20DeFi%20platforms%20and%20real-time%20financial%20metrics.&page=2\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Resources\n",
      "  - 서버 데이터 추출: Alpha Vantage MCP Server\n",
      "  - 서버 데이터 추출: Q-Anon Posts/Drops Server\n",
      "  - 서버 데이터 추출: Jupiter Swap API Server\n",
      "  - 서버 데이터 추출: Veri5ight\n",
      "  - 서버 데이터 추출: PancakeSwap PoolSpy\n",
      "  - 서버 데이터 추출: Crypto Price Query Server\n",
      "  - 서버 데이터 추출: Hyperliquid MCP Server\n",
      "  - 서버 데이터 추출: Crypto Market Maker Dashboard\n",
      "  - 서버 데이터 추출: Whale Tracker\n",
      "  - 서버 데이터 추출: DexScreener API Access\n",
      "  - 서버 데이터 추출: Cryptocurrency Market Data Server\n",
      "  - 서버 데이터 추출: Crypto Whale Tracker\n",
      "  - 서버 데이터 추출: Cryptocurrency Data\n",
      "  - 서버 데이터 추출: Financial Datasets MCP Server\n",
      "  - 서버 데이터 추출: Crypto Sentiment Analysis Server\n",
      "  - 서버 데이터 추출: Binance Market Data Server\n",
      "  - 서버 데이터 추출: Bitcoin Price MCP Server\n",
      "  - 서버 데이터 추출: Cryptocurrency Price Service\n",
      "  - 서버 데이터 추출: Crypto Price & Market Analysis Server\n",
      "  - 서버 데이터 추출: Bybit MCP Server\n",
      "페이지 2 완료: 21개 서버 추출 (쿼리 누적: 42개)\n",
      "다음 요청까지 2.16초 대기 중...\n",
      "\n",
      "검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' - 페이지 3 로드 중: https://smithery.ai/?q=Explore%20servers%20that%20provide%20advanced%20tools%20for%20tracking%20and%20analyzing%20cryptocurrency%20transactions%2C%20liquidity%20pools%2C%20and%20financial%20market%20data%2C%20including%20integrations%20with%20DeFi%20platforms%20and%20real-time%20financial%20metrics.&page=3\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Resources\n",
      "  - 서버 데이터 추출: Solana Trading Server\n",
      "  - 서버 데이터 추출: CoinGecko API Server\n",
      "  - 서버 데이터 추출: OpenLedger MCP Server\n",
      "  - 서버 데이터 추출: Etherscan Tools\n",
      "  - 서버 데이터 추출: AlphaVantage MCP Server\n",
      "  - 서버 데이터 추출: CoinGecko Server\n",
      "  - 서버 데이터 추출: CoinMarketCap MCP Server\n",
      "  - 서버 데이터 추출: CCXT MCP Server\n",
      "  - 서버 데이터 추출: Binance Trading Server\n",
      "  - 서버 데이터 추출: CoinGecko API Server\n",
      "  - 서버 데이터 추출: KOSPI/KOSDAQ Stock Data Server\n",
      "  - 서버 데이터 추출: OKX Server\n",
      "  - 서버 데이터 추출: Financial Datasets SDK\n",
      "  - 서버 데이터 추출: Shioaji Trading API Server\n",
      "  - 서버 데이터 추출: Cryptocurrency Daemon Server\n",
      "  - 서버 데이터 추출: EDUCHAIN Agent Kit\n",
      "  - 서버 데이터 추출: Cryptocurrency News Server\n",
      "  - 서버 데이터 추출: Crypto News Server\n",
      "  - 서버 데이터 추출: Stock Analysis Server\n",
      "  - 서버 데이터 추출: Alpha Vantage MCP Server\n",
      "페이지 3 완료: 21개 서버 추출 (쿼리 누적: 63개)\n",
      "다음 요청까지 2.03초 대기 중...\n",
      "\n",
      "검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' - 페이지 4 로드 중: https://smithery.ai/?q=Explore%20servers%20that%20provide%20advanced%20tools%20for%20tracking%20and%20analyzing%20cryptocurrency%20transactions%2C%20liquidity%20pools%2C%20and%20financial%20market%20data%2C%20including%20integrations%20with%20DeFi%20platforms%20and%20real-time%20financial%20metrics.&page=4\n",
      "발견된 서버 카드: 42개\n",
      "  - 서버 데이터 추출: Resources\n",
      "  - 서버 데이터 추출: Query Table\n",
      "  - 서버 데이터 추출: Solana Trading Server\n",
      "  - 서버 데이터 추출: Futures Strategy Manager\n",
      "  - 서버 데이터 추출: Bankless Onchain Server\n",
      "  - 서버 데이터 추출: XTB API Server\n",
      "  - 서버 데이터 추출: Upbit API\n",
      "  - 서버 데이터 추출: Alchemy Plugin\n",
      "  - 서버 데이터 추출: Financial Analyzer\n",
      "  - 서버 데이터 추출: Octagon MCP Server\n",
      "  - 서버 데이터 추출: Opus AI Trader\n",
      "  - 서버 데이터 추출: 量化研究与交易平台\n",
      "  - 서버 데이터 추출: Paradex Server\n",
      "  - 서버 데이터 추출: Fiscal Data Server\n",
      "  - 서버 데이터 추출: Blockchain Query Server\n",
      "  - 서버 데이터 추출: Alpaca Trading MCP Server\n",
      "  - 서버 데이터 추출: AKShare MCP Server\n",
      "  - 서버 데이터 추출: Tushare数据查询服务器\n",
      "  - 서버 데이터 추출: Ledger Service\n",
      "  - 서버 데이터 추출: XTQuantAI\n",
      "  - 서버 데이터 추출: Ethereum Address Info Server\n",
      "페이지 4 완료: 21개 서버 추출 (쿼리 누적: 84개)\n",
      "다음 요청까지 2.33초 대기 중...\n",
      "\n",
      "검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' - 페이지 5 로드 중: https://smithery.ai/?q=Explore%20servers%20that%20provide%20advanced%20tools%20for%20tracking%20and%20analyzing%20cryptocurrency%20transactions%2C%20liquidity%20pools%2C%20and%20financial%20market%20data%2C%20including%20integrations%20with%20DeFi%20platforms%20and%20real-time%20financial%20metrics.&page=5\n",
      "발견된 서버 카드: 28개\n",
      "  - 서버 데이터 추출: Resources\n",
      "  - 서버 데이터 추출: Lighthouse\n",
      "  - 서버 데이터 추출: ExploitDB Integration Server\n",
      "  - 서버 데이터 추출: Deep Web Research Server\n",
      "  - 서버 데이터 추출: Ledger CLI MCP Server\n",
      "  - 서버 데이터 추출: Soccer Data Server\n",
      "  - 서버 데이터 추출: RootData MCP Server\n",
      "  - 서버 데이터 추출: Ledger CLI MCP Server\n",
      "  - 서버 데이터 추출: OpenDeepSearch\n",
      "  - 서버 데이터 추출: Angle One MCP Server\n",
      "  - 서버 데이터 추출: DataForSEO API Server\n",
      "  - 서버 데이터 추출: Juhe Exchange Rates\n",
      "  - 서버 데이터 추출: Flow MCP Server\n",
      "  - 서버 데이터 추출: Beancount MCP Server\n",
      "페이지 5 완료: 14개 서버 추출 (쿼리 누적: 98개)\n",
      "\n",
      "=== 검색어 'Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.' 크롤링 완료 (총 98개 서버) ===\n",
      "데이터 저장 완료: Financial Data & Analysis.csv (98개 서버)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_query</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>usage_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explore servers that provide advanced tools fo...</td>\n",
       "      <td>Resources</td>\n",
       "      <td>Building the operating system for AI</td>\n",
       "      <td>https://smithery.ai/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explore servers that provide advanced tools fo...</td>\n",
       "      <td>Crypto Price &amp; Market Analysis Server</td>\n",
       "      <td>Provide real-time cryptocurrency price data an...</td>\n",
       "      <td>https://smithery.ai/server/@truss44/mcp-crypto...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>9.35k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explore servers that provide advanced tools fo...</td>\n",
       "      <td>Lunchmoney MCP Server</td>\n",
       "      <td>Interact with your Lunchmoney transactions and...</td>\n",
       "      <td>https://smithery.ai/server/@leafeye/lunchmoney...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>6.68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explore servers that provide advanced tools fo...</td>\n",
       "      <td>MCP Server Starter</td>\n",
       "      <td>Build a robust server to enable AI agents to i...</td>\n",
       "      <td>https://smithery.ai/server/@TheSethRose/mcp-se...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>3.79k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explore servers that provide advanced tools fo...</td>\n",
       "      <td>Alpha Vantage Stock Server</td>\n",
       "      <td>Access real-time and historical stock market d...</td>\n",
       "      <td>https://smithery.ai/server/@qubaomingg/stock-a...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        search_query  \\\n",
       "0  Explore servers that provide advanced tools fo...   \n",
       "1  Explore servers that provide advanced tools fo...   \n",
       "2  Explore servers that provide advanced tools fo...   \n",
       "3  Explore servers that provide advanced tools fo...   \n",
       "4  Explore servers that provide advanced tools fo...   \n",
       "\n",
       "                                    name  \\\n",
       "0                              Resources   \n",
       "1  Crypto Price & Market Analysis Server   \n",
       "2                  Lunchmoney MCP Server   \n",
       "3                     MCP Server Starter   \n",
       "4             Alpha Vantage Stock Server   \n",
       "\n",
       "                                         description  \\\n",
       "0               Building the operating system for AI   \n",
       "1  Provide real-time cryptocurrency price data an...   \n",
       "2  Interact with your Lunchmoney transactions and...   \n",
       "3  Build a robust server to enable AI agents to i...   \n",
       "4  Access real-time and historical stock market d...   \n",
       "\n",
       "                                                 url    type usage_count  \n",
       "0                               https://smithery.ai/     NaN         NaN  \n",
       "1  https://smithery.ai/server/@truss44/mcp-crypto...  Remote       9.35k  \n",
       "2  https://smithery.ai/server/@leafeye/lunchmoney...  Remote       6.68k  \n",
       "3  https://smithery.ai/server/@TheSethRose/mcp-se...  Remote       3.79k  \n",
       "4  https://smithery.ai/server/@qubaomingg/stock-a...  Remote         NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install requests beautifulsoup4 pandas tqdm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import urllib.parse\n",
    "from tqdm.notebook import tqdm  # 주피터 노트북용 진행 표시줄\n",
    "\n",
    "class SmitheryMultiQueryCrawler:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Smithery.ai crawler for multiple search queries\n",
    "        \"\"\"\n",
    "        # 쿠키와 헤더 설정\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Referer': 'https://smithery.ai/',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # 모든 서버 데이터를 저장할 리스트\n",
    "        self.all_data = []\n",
    "    \n",
    "    def random_sleep(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"\n",
    "        Sleep for a random amount of time\n",
    "        \n",
    "        Args:\n",
    "            min_seconds (float): Minimum sleep time in seconds\n",
    "            max_seconds (float): Maximum sleep time in seconds\n",
    "        \"\"\"\n",
    "        sleep_time = random.uniform(min_seconds, max_seconds)\n",
    "        print(f\"다음 요청까지 {sleep_time:.2f}초 대기 중...\")\n",
    "        time.sleep(sleep_time)\n",
    "    \n",
    "    def get_page(self, query, page_number=1):\n",
    "        \"\"\"\n",
    "        Get the HTML content of a specific search query and page\n",
    "        \n",
    "        Args:\n",
    "            query (str): Search query\n",
    "            page_number (int): Page number to fetch\n",
    "        \n",
    "        Returns:\n",
    "            BeautifulSoup: Parsed HTML content\n",
    "        \"\"\"\n",
    "        # URL 인코딩 적용\n",
    "        encoded_query = urllib.parse.quote(query)\n",
    "        url = f\"https://smithery.ai/?q={encoded_query}&page={page_number}\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n검색어 '{query}' - 페이지 {page_number} 로드 중: {url}\")\n",
    "            response = self.session.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return BeautifulSoup(response.text, 'html.parser')\n",
    "            else:\n",
    "                print(f\"Error: HTTP {response.status_code} - {url}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"페이지 로드 중 오류 발생: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_max_pages(self, soup):\n",
    "        \"\"\"\n",
    "        Get the maximum number of pages for the current search query\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML content of the first page\n",
    "        \n",
    "        Returns:\n",
    "            int: Maximum number of pages, defaults to 1 if not found\n",
    "        \"\"\"\n",
    "        if soup is None:\n",
    "            return 1\n",
    "        \n",
    "        try:\n",
    "            # 페이지네이션 요소에서 마지막 페이지 번호 찾기\n",
    "            pagination = soup.select('nav ul li a') or soup.select('nav ul a')\n",
    "            max_page = 1\n",
    "            \n",
    "            for a in pagination:\n",
    "                text = a.get_text().strip()\n",
    "                if text.isdigit():\n",
    "                    page_num = int(text)\n",
    "                    max_page = max(max_page, page_num)\n",
    "            \n",
    "            # 페이지 번호가 발견되지 않으면 href 속성에서 찾기\n",
    "            if max_page == 1:\n",
    "                for a in pagination:\n",
    "                    if a.has_attr('href'):\n",
    "                        href = a['href']\n",
    "                        match = re.search(r'page=(\\d+)', href)\n",
    "                        if match:\n",
    "                            page_num = int(match.group(1))\n",
    "                            max_page = max(max_page, page_num)\n",
    "            \n",
    "            print(f\"검색 결과 최대 페이지 수: {max_page}\")\n",
    "            return max_page\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"최대 페이지 수 확인 중 오류 발생: {str(e)}\")\n",
    "            return 1\n",
    "    \n",
    "    def extract_server_data(self, soup, query):\n",
    "        \"\"\"\n",
    "        Extract server data from a BeautifulSoup object\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML content\n",
    "            query (str): The search query used\n",
    "        \n",
    "        Returns:\n",
    "            list: List of dictionaries containing server data\n",
    "        \"\"\"\n",
    "        servers_data = []\n",
    "        \n",
    "        if soup is None:\n",
    "            return servers_data\n",
    "        \n",
    "        try:\n",
    "            # 카드를 찾기 위한 다양한 선택자 시도\n",
    "            server_cards = (\n",
    "                soup.select('.card') or \n",
    "                soup.select('[class*=\"card\"]') or \n",
    "                soup.select('a[href*=\"/smithery-ai/\"]') or\n",
    "                soup.select('a[href*=\"smithery.ai\"]') or\n",
    "                soup.select('main > div > div > div > div > a') or\n",
    "                # 추가 선택자 - 가능한 모든 서버 카드 포함\n",
    "                soup.select('div > a[href]')\n",
    "            )\n",
    "            \n",
    "            print(f\"발견된 서버 카드: {len(server_cards)}개\")\n",
    "            \n",
    "            for card in server_cards:\n",
    "                server = {}\n",
    "                \n",
    "                # 검색 쿼리 추가\n",
    "                server['search_query'] = query\n",
    "                \n",
    "                # 서버 이름 추출 시도\n",
    "                name_element = (\n",
    "                    card.select_one('h2') or \n",
    "                    card.select_one('h3') or \n",
    "                    card.select_one('h3 > span') or\n",
    "                    card.select_one('div > h3') or\n",
    "                    card.select_one('div > h3 > span') or\n",
    "                    card.select_one('span[class*=\"title\"]') or\n",
    "                    card.select_one('div[class*=\"title\"]')\n",
    "                )\n",
    "                \n",
    "                if name_element:\n",
    "                    server['name'] = name_element.get_text().strip()\n",
    "                \n",
    "                # 서버 핸들 추출 (@로 시작하는 텍스트)\n",
    "                texts = card.get_text().split('\\n')\n",
    "                for text in texts:\n",
    "                    text = text.strip()\n",
    "                    if text.startswith('@'):\n",
    "                        server['handle'] = text\n",
    "                        break\n",
    "                \n",
    "                # 설명 추출\n",
    "                desc_element = (\n",
    "                    card.select_one('p') or \n",
    "                    card.select_one('div > p') or\n",
    "                    card.select_one('div[class*=\"description\"]')\n",
    "                )\n",
    "                \n",
    "                if desc_element and not desc_element.get_text().strip().startswith('@'):\n",
    "                    server['description'] = desc_element.get_text().strip()\n",
    "                else:\n",
    "                    # 설명을 찾을 수 없는 경우 모든 텍스트 블록을 검사\n",
    "                    for p in card.select('p'):\n",
    "                        text = p.get_text().strip()\n",
    "                        if text and not text.startswith('@'):\n",
    "                            server['description'] = text\n",
    "                            break\n",
    "                \n",
    "                # URL 추출\n",
    "                if card.name == 'a' and card.has_attr('href'):\n",
    "                    url = card['href']\n",
    "                    if not url.startswith('http'):\n",
    "                        url = f\"https://smithery.ai{url}\"\n",
    "                    server['url'] = url\n",
    "                else:\n",
    "                    url_element = card.select_one('a')\n",
    "                    if url_element and url_element.has_attr('href'):\n",
    "                        url = url_element['href']\n",
    "                        if not url.startswith('http'):\n",
    "                            url = f\"https://smithery.ai{url}\"\n",
    "                        server['url'] = url\n",
    "                \n",
    "                # 유형 및 사용량 추출\n",
    "                for span in card.select('span'):\n",
    "                    text = span.get_text().strip()\n",
    "                    if text in ['Remote', 'Local']:\n",
    "                        server['type'] = text\n",
    "                    elif text.endswith('k') and any(c.isdigit() for c in text):\n",
    "                        server['usage_count'] = text\n",
    "                \n",
    "                # 이름이나 핸들이 있는 서버만 추가\n",
    "                if server.get('name') or server.get('handle'):\n",
    "                    servers_data.append(server)\n",
    "                    print(f\"  - 서버 데이터 추출: {server.get('name', server.get('handle', '알 수 없음'))}\")\n",
    "            \n",
    "            return servers_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"서버 데이터 추출 중 오류 발생: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return servers_data\n",
    "    \n",
    "    def extract_server_details(self, url):\n",
    "        \"\"\"\n",
    "        Extract additional details from a server's page\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the server's page\n",
    "        \n",
    "        Returns:\n",
    "            dict: Additional details about the server\n",
    "        \"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        try:\n",
    "            self.random_sleep(0.5, 1.5)  # 짧은 대기 시간\n",
    "            \n",
    "            response = self.session.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"  - 서버 상세 정보 로드 실패: HTTP {response.status_code}\")\n",
    "                return details\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # 라이선스 정보 추출\n",
    "            license_elements = soup.find_all(string=re.compile('License', re.I))\n",
    "            for element in license_elements:\n",
    "                parent = element.parent\n",
    "                if parent and parent.name in ['dt', 'h3', 'h4', 'strong', 'b', 'span']:\n",
    "                    sibling = parent.find_next_sibling()\n",
    "                    if sibling:\n",
    "                        details['license'] = sibling.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            # 출시일 추출\n",
    "            publish_elements = soup.find_all(string=re.compile('Published', re.I))\n",
    "            for element in publish_elements:\n",
    "                parent = element.parent\n",
    "                if parent and parent.name in ['dt', 'h3', 'h4', 'strong', 'b', 'span']:\n",
    "                    sibling = parent.find_next_sibling()\n",
    "                    if sibling:\n",
    "                        details['published_date'] = sibling.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            # 설치 명령어 추출\n",
    "            install_elements = soup.find_all(string=re.compile('Installation|Install', re.I))\n",
    "            for element in install_elements:\n",
    "                parent = element.parent\n",
    "                if parent:\n",
    "                    code_block = parent.find_next('code') or parent.find_next('pre')\n",
    "                    if code_block:\n",
    "                        details['installation'] = code_block.get_text().strip()\n",
    "                        break\n",
    "            \n",
    "            return details\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - 서버 상세 정보 추출 중 오류 발생: {str(e)}\")\n",
    "            return details\n",
    "    \n",
    "    def crawl_query(self, query, max_pages=None, get_details=False):\n",
    "        \"\"\"\n",
    "        Crawl all pages for a specific search query\n",
    "        \n",
    "        Args:\n",
    "            query (str): Search query to crawl\n",
    "            max_pages (int, optional): Maximum number of pages to crawl. If None, automatically detect.\n",
    "            get_details (bool): Whether to fetch additional details from each server's page\n",
    "        \n",
    "        Returns:\n",
    "            list: Scraped data for this query\n",
    "        \"\"\"\n",
    "        query_data = []\n",
    "        \n",
    "        # 첫 페이지 가져오기\n",
    "        first_page_soup = self.get_page(query, 1)\n",
    "        \n",
    "        # 최대 페이지 수 확인\n",
    "        if max_pages is None:\n",
    "            max_pages = self.get_max_pages(first_page_soup)\n",
    "        \n",
    "        # 첫 페이지 데이터 추출\n",
    "        first_page_data = self.extract_server_data(first_page_soup, query)\n",
    "        query_data.extend(first_page_data)\n",
    "        \n",
    "        # 상세 정보 추출 (선택 사항)\n",
    "        if get_details and first_page_data:\n",
    "            print(\"서버 상세 정보 추출 중...\")\n",
    "            for server in tqdm(first_page_data, desc=\"서버 상세 정보\"):\n",
    "                if 'url' in server:\n",
    "                    details = self.extract_server_details(server['url'])\n",
    "                    server.update(details)\n",
    "        \n",
    "        print(f\"페이지 1 완료: {len(first_page_data)}개 서버 추출\")\n",
    "        \n",
    "        # 2페이지부터 크롤링\n",
    "        for page_number in tqdm(range(2, max_pages + 1), desc=f\"'{query}' 검색 결과 페이지 크롤링\"):\n",
    "            # 다음 페이지로 이동 전 대기\n",
    "            self.random_sleep()\n",
    "            \n",
    "            # 페이지 로드\n",
    "            soup = self.get_page(query, page_number)\n",
    "            \n",
    "            # 서버 데이터 추출\n",
    "            page_data = self.extract_server_data(soup, query)\n",
    "            \n",
    "            # 상세 정보 추출 (선택 사항)\n",
    "            if get_details and page_data:\n",
    "                print(\"서버 상세 정보 추출 중...\")\n",
    "                for server in tqdm(page_data, desc=\"서버 상세 정보\"):\n",
    "                    if 'url' in server:\n",
    "                        details = self.extract_server_details(server['url'])\n",
    "                        server.update(details)\n",
    "            \n",
    "            # 결과 저장\n",
    "            query_data.extend(page_data)\n",
    "            \n",
    "            print(f\"페이지 {page_number} 완료: {len(page_data)}개 서버 추출 (쿼리 누적: {len(query_data)}개)\")\n",
    "        \n",
    "        # 모든 데이터에 결과 추가\n",
    "        self.all_data.extend(query_data)\n",
    "        \n",
    "        return query_data\n",
    "    \n",
    "    def crawl_multiple_queries(self, queries, max_pages=None, get_details=False):\n",
    "        \"\"\"\n",
    "        Crawl multiple search queries\n",
    "        \n",
    "        Args:\n",
    "            queries (list): List of search queries to crawl\n",
    "            max_pages (int, optional): Maximum number of pages to crawl per query\n",
    "            get_details (bool): Whether to fetch additional details from each server's page\n",
    "        \n",
    "        Returns:\n",
    "            list: All scraped data\n",
    "        \"\"\"\n",
    "        # 초기화\n",
    "        self.all_data = []\n",
    "        \n",
    "        # 각 쿼리 크롤링\n",
    "        for query in queries:\n",
    "            print(f\"\\n\\n=== 검색어 '{query}' 크롤링 시작 ===\\n\")\n",
    "            self.crawl_query(query, max_pages, get_details)\n",
    "            print(f\"\\n=== 검색어 '{query}' 크롤링 완료 (총 {len(self.all_data)}개 서버) ===\")\n",
    "        \n",
    "        return self.all_data\n",
    "    \n",
    "    def save_to_csv(self, filename=\"smithery_all_queries.csv\"):\n",
    "        \"\"\"\n",
    "        Save the scraped data to a CSV file\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Name of the CSV file to save\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the scraped data\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.all_data)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"데이터 저장 완료: {filename} ({len(self.all_data)}개 서버)\")\n",
    "        return df\n",
    "\n",
    "# 설정값\n",
    "QUERIES = [\n",
    "    \"is:deployed\",  # 기본 검색어\n",
    "    \"web search\"    # 추가 검색어\n",
    "]\n",
    "MAX_PAGES = 10       # 각 검색어당 최대 페이지 수 (None으로 설정하면 자동 감지)\n",
    "GET_DETAILS = False  # 서버 상세 정보 추출 여부\n",
    "OUTPUT_FILE = \"smithery_all_servers.csv\"  # 결과 파일명\n",
    "\n",
    "# 크롤러 실행 함수\n",
    "def run_crawler(queries=QUERIES, max_pages=MAX_PAGES, get_details=GET_DETAILS, output_file=OUTPUT_FILE):\n",
    "    \"\"\"\n",
    "    Smithery.ai 크롤러를 실행하고 결과를 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        queries (list): 크롤링할 검색어 목록\n",
    "        max_pages (int): 각 검색어당 크롤링할 최대 페이지 수\n",
    "        get_details (bool): 서버 상세 정보 추출 여부\n",
    "        output_file (str): 결과 파일명\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 크롤링 결과\n",
    "    \"\"\"\n",
    "    # 크롤러 초기화\n",
    "    crawler = SmitheryMultiQueryCrawler()\n",
    "    \n",
    "    # 크롤링 수행\n",
    "    crawler.crawl_multiple_queries(queries, max_pages, get_details)\n",
    "    \n",
    "    # 결과 저장 및 반환\n",
    "    df = crawler.save_to_csv(output_file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 아래 주석을 제거하고 실행하세요\n",
    "# df = run_crawler(queries=[\"is:deployed\", \"web search\"], max_pages=5)\n",
    "# df.head()  # 결과 확인\n",
    "\n",
    "# 개별 검색어 테스트\n",
    "# df_web_search = run_crawler(queries=[\"web search\"], max_pages=6, output_file=\"smithery_web_search.csv\")\n",
    "# df_web_search.head()\n",
    "\n",
    "# df_advanced_web_browsing_automation = run_crawler(queries=[\"advanced web browsing automation\"], max_pages=4, output_file=\"smithery_advanced_web_browsing_automation.csv\")\n",
    "# df_advanced_web_browsing_automation.head()\n",
    "\n",
    "# df_dynamic_web_development = run_crawler(queries=[\"Tools and frameworks for building dynamic web applications and integrating real-time data\"], max_pages=5, output_file=\"Tools and frameworks for building dynamic web applications and integrating real-time data.csv\")\n",
    "# df_dynamic_web_development.head() \n",
    "\n",
    "\n",
    "# df_ApplicationIntegrationToolst = run_crawler(queries=[\"Integrate applications with real-world data and external APIs for enhanced workflows and dynamic interactions. Explore servers enabling seamless integration with tools like Anki, Warpcast, and Beamlit for diverse operations.\"], max_pages=18, output_file=\"Application Integration Tools.csv\")\n",
    "# df_ApplicationIntegrationToolst.head() \n",
    "\n",
    "df_FinancialData_Analysis = run_crawler(queries=[\"Explore servers that provide advanced tools for tracking and analyzing cryptocurrency transactions, liquidity pools, and financial market data, including integrations with DeFi platforms and real-time financial metrics.\"], max_pages=5, output_file=\"Financial Data & Analysis.csv\")\n",
    "df_FinancialData_Analysis.head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
